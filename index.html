<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="我菜故我在">
<meta property="og:type" content="website">
<meta property="og:title" content="小菜鸡">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="小菜鸡">
<meta property="og:description" content="我菜故我在">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="小菜鸡">
<meta name="twitter:description" content="我菜故我在">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>小菜鸡</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-106410509-1', 'auto');
  ga('send', 'pageview');
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->





</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">小菜鸡</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/21/算法工程师技能加点路线/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jeb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小菜鸡">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/21/算法工程师技能加点路线/" itemprop="url">算法工程师技能加点路线</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-04-21T11:12:09+08:00">
                2020-04-21
              </time>
            

            
              <i class="fa fa-thumb-tack"></i>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>下图为2018年LOL段位的统计数据：</p>
<p><img width="500" src="/images/lol.jpeg"></p>
<p>参考LOL的段位体系，先制定一个小目标，在算法工程师（Base NLP）中达到黄金段位。下图整理了自己准备进入游戏时带的技能包，数字1，2，3表示学技能的优先级，绿色饼状图表示掌握该技能的经验值。</p>
<p>技能掌握包含三个方面：</p>
<ol>
<li>理论知识。需要全面总结并包含自己的理解，以博客文章形式输出；</li>
<li>工程实践。需要动手实验并记录总结，以博客文章形式输出；</li>
<li>代码编写。需要整理源码或自己编码， 并push到Github上。</li>
</ol>
<p>同时要关注算法行业的最新发展趋势，与时俱进，不断扩展技能包。</p>
<p><img src="/images/alg.png"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/22/常用推荐模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jeb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小菜鸡">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/10/22/常用推荐模型/" itemprop="url">常用推荐模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-10-22T18:07:04+08:00">
                2020-10-22
              </time>
            

            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>搜索和推荐系统一般包含召回和排序两个阶段，搜索排序主要关注相关性，常见的模型可以参考<a href="http://octopuscoder.github.io/2020/01/19/搜索排序算法/" target="_blank" rel="external">搜索排序算法</a>。推荐模型则关注用户偏好，一般用CTR点击率来描述，常用的推荐模型有：</p>
<p><img src="/images/rec1.jpg" alt=""></p>
<blockquote>
<p>图片来源：<a href="https://zhuanlan.zhihu.com/p/243243145" target="_blank" rel="external">推荐算法炼丹笔记：CTR点击率预估系列入门手册</a></p>
</blockquote>
<p>本文重点关注应用较为广泛的LR、GBDT、FM、Wide&amp;Deep和DIN模型，其中LR、GBDT和FM部分大部分图片引用自<a href="http://www.zhihu.com/column/c_1151830542046711808" target="_blank" rel="external">刘启林的机器学习笔记</a>。</p>
<h1 id="模型介绍"><a href="#模型介绍" class="headerlink" title="模型介绍"></a>模型介绍</h1><h2 id="LR"><a href="#LR" class="headerlink" title="LR"></a>LR</h2><p>下面从逻辑回归LR的假设、原理和训练等方面进行介绍。</p>
<h3 id="LR假设"><a href="#LR假设" class="headerlink" title="LR假设"></a>LR假设</h3><ol>
<li>数据服从伯努利分布；</li>
<li>样本概率是Sigmoid函数。</li>
</ol>
<p><img src="/images/lrjs.png" alt=""></p>
<h3 id="LR原理"><a href="#LR原理" class="headerlink" title="LR原理"></a>LR原理</h3><p>逻辑回归模型是由线性回归模型和Sigmoid函数共同组成的：</p>
<p><img src="/images/lryl.png" alt="img"></p>
<p>Sigmoid函数：</p>
<p><img src="/images/sigmoid.png" alt="img"></p>
<p>线性回归定义：</p>
<p><img src="/images/lrre.png" alt="img"></p>
<p>线性回归假设：</p>
<p><img src="/images/lrjs-2.png" alt="img"></p>
<p>一元线性回归：</p>
<p><img src="/images/lirejc.png" alt="img"></p>
<p>多元线性回归：</p>
<p><img src="/images/dylire.png" alt="img"></p>
<p>线性回归模型：</p>
<p><img src="/images/liremodel-1.png" alt="img"></p>
<p>回到逻辑回归，LR一般用于分类任务，其中二分类的原理如下：</p>
<p><img src="/images/lrbincl.png" alt="img"></p>
<h3 id="LR训练"><a href="#LR训练" class="headerlink" title="LR训练"></a>LR训练</h3><p>根据二项分布构建似然函数，为方便进行训练转化为对数似然函数，并通过极大似然估计方法进行参数训练：</p>
<p><img src="/images/lrtrain.png" alt="img"></p>
<p>极大似然估计是一种参数估计方法，使用的前提条件是：<strong>训练样本的分布能代表样本的真实分布。每个样本集中的样本都是所谓独立同分布的随机变量 ，且有充分的训练样本。</strong>极大似然估计（Maximum Likelihood Estimation）的原理可以用下图说明：</p>
<p><img src="/images/maxlike.png" alt="img"></p>
<p><strong>极大似然估计的目的：利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值，即：“模型已定，参数未知”。</strong></p>
<p>考虑一个样本集<span>$D=\left\{x_{1}, x_{2}, \ldots, x_{n}\right\}$</span><!-- Has MathJax -->，我们需要对参数<span>$\theta$</span><!-- Has MathJax -->进行估计。<strong>似然函数</strong>定义为联合密度函数<span>$p(D \mid \theta)$</span><!-- Has MathJax -->：</p>
<span>$l(\theta)=p(D \mid \theta)=p\left(x_{1}, x_{2}, \ldots, x_{n} \mid \theta\right)=\prod_{i=1}^{n} p\left(x_{i} \mid \theta\right)$</span><!-- Has MathJax -->
<p>如果<span>$\hat{\theta}$</span><!-- Has MathJax -->是参数空间中使似然函数最大的<span>$\theta$</span><!-- Has MathJax -->值，那么<span>$\hat{\theta}$</span><!-- Has MathJax -->应该就是“最可能”的参数值，<span>$\hat{\theta}$</span><!-- Has MathJax -->就是<span>$\theta$</span><!-- Has MathJax -->的极大似然估计量。联合密度函数连乘求导比较麻烦，一般取对数后转换为叠加进行求解。</p>
<p>利用梯度下降法进行训练：</p>
<p><img src="/images/lrgd-1.png" alt="img"></p>
<p>LR梯度下降公式还是很简洁的：</p>
<p><img src="/images/lrgd.png" alt="img"></p>
<p>而在训练模型时，我们通常使用损失函数，这里如果取整个数据集上的平均对数似然损失可以得到：<span>$J(w)=-\frac{1}{N} \ln L(w)$</span><!-- Has MathJax --></p>
<p>显然在逻辑回归模型中，最大化似然函数和最小化损失函数其实是等价的。</p>
<h3 id="LR扩展知识点"><a href="#LR扩展知识点" class="headerlink" title="LR扩展知识点"></a>LR扩展知识点</h3><h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><p><img src="/images/lryqd.png" alt="img"></p>
<h4 id="对比线性回归"><a href="#对比线性回归" class="headerlink" title="对比线性回归"></a>对比线性回归</h4><p><img src="/images/lirvslor.png" alt="img"></p>
<h4 id="多分类"><a href="#多分类" class="headerlink" title="多分类"></a>多分类</h4><p>多项逻辑回归</p>
<p><img src="/images/dxslre.png" alt="img"></p>
<p>Softmax回归：</p>
<p><img src="/images/smre.png" alt="img"></p>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>为什么不适用平方误差作为损失函数？</p>
<ol>
<li>平方误差损失函数加上sigmoid的函数将会是一个非凸的函数，不易求解，会得到局部解，用对数似然函数得到高阶连续可导凸函数，可以得到最优解。</li>
<li>对数损失函数更新起来很快，因为只和x，y有关，和sigmoid本身的梯度无关。如果使用平方损失函数，会发现梯度更新的速度和sigmod函数本身的梯度是很相关的。sigmod函数在它在定义域内的梯度都不大于0.25。这样训练会非常的慢。</li>
</ol>
<h4 id="特征离散化"><a href="#特征离散化" class="headerlink" title="特征离散化"></a>特征离散化</h4><p>为什么逻辑回归一般会进行特征离散化处理：</p>
<ol>
<li>非线性：逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合； 离散特征的增加和减少都很容易，易于模型的快速迭代；</li>
<li>速度快：稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展；</li>
<li>鲁棒性：离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄&gt;30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰；</li>
<li>方便交叉与特征组合：离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力；</li>
<li>稳定性：特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问；</li>
<li>简化模型：特征离散化以后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。</li>
</ol>
<h4 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h4><p>用于避免过拟合，一般采用L1或L2正则化。L1 正则的本质其实是为模型增加了“模型参数服从零均值拉普拉斯分布”这一先验知识，L1会趋向于产生少量的特征，而其他的特征都是0(稀疏性)。 L2 正则的本质其实是为模型增加了“模型参数服从零均值正态分布”这一先验知识，L2会选择更多的特征，这些特征都会接近于0。L1在特征选择时候非常有用，而L2只是一种规则化。L1范数可以使权值稀疏，方便特征提取。L2范数可以防止过拟合，提升模型的泛化能力。</p>
<h2 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h2><p>FM（Factor Machine，因子分解机）是一种基于矩阵分解的机器学习算法，用于解决大规模稀疏矩阵中特征组合问题，可以看做针对上文中提到的线性模型的改进，回顾一下线性回归模型：</p>
<p><img src="/images/liremodel.png" alt="img"></p>
<p>线性回归模型假设特征之间是相互独立的、不相关的。但在现实的某些场景中，特征之间往往是相关的，而不是相互独立的。比如&lt;女人&gt;和&lt;化妆品&gt;，&lt;男人&gt;与&lt;足球&gt;等，所以需要特征组合。一种简单的做法是将特征进行两两组合，如下图所示：</p>
<p><img src="/images/fmzh.png" alt="img"></p>
<p>我们可以利用二阶多项式回归模型对此进行建模：</p>
<p><img src="/images/dxshg.png" alt="img"></p>
<h3 id="矩阵分解-Matrix-Factorization-vs-因子分解机-Factor-Machine"><a href="#矩阵分解-Matrix-Factorization-vs-因子分解机-Factor-Machine" class="headerlink" title="矩阵分解(Matrix Factorization) vs 因子分解机(Factor Machine)"></a>矩阵分解(Matrix Factorization) vs 因子分解机(Factor Machine)</h3><p>MF（Matrix Factorization，矩阵分解）在推荐系统已经得到广泛应用，最典型的代表就是协同过滤模型。其核心思想是通过两个低维小矩阵（一个代表用户embedding矩阵，一个代表物品embedding矩阵）的乘积计算，来模拟真实用户点击或评分产生的大的协同信息稀疏矩阵，本质上是编码了用户和物品协同信息的降维模型，如下图所示：</p>
<p><img src="/images/mfyl-wb.png" alt="img"></p>
<blockquote>
<p>图片来源：<a href="https://zhuanlan.zhihu.com/p/58160982" target="_blank" rel="external">推荐系统召回四模型之：全能的FM模型</a></p>
</blockquote>
<p>当训练完成，每个用户和物品得到对应的低维embedding表达后，如果要预测某个<span>$User_{i}$</span><!-- Has MathJax -->对<span>$Item_{j}$</span><!-- Has MathJax --> 的评分的时候，只要它们做个内积计算<span>$&lt;User_{i},Item_{j}&gt;$</span><!-- Has MathJax --> ，这个得分就是预测得分:</p>
<p><img src="/images/fmyl-wb.png" alt="img"></p>
<p>MF和FM不仅在名字简称上看着有点像，其实他们本质思想上也有很多相同点。本质上，MF模型是FM模型的特例，MF可以被认为是只有User ID 和Item ID这两个特征Fields的FM模型，MF将这两类特征通过矩阵分解，来达到将这两类特征embedding化表达的目的。而FM则可以看作是MF模型的进一步拓展，除了User ID和Item ID这两类特征外，很多其它类型的特征，都可以进一步融入FM模型里，它将所有这些特征转化为embedding低维向量表达，并计算任意两个特征embedding的内积，就是特征组合的权重，如下图所示：</p>
<p><img src="/images/mf2fm.png" alt="img"></p>
<h3 id="FM模型原理"><a href="#FM模型原理" class="headerlink" title="FM模型原理"></a>FM模型原理</h3><p>从下图中公式可以看出，公式前半部分是线性模型，后半部分是特征交叉项。因此多项式回归模型的特征组合能力要强于线性模型，而当交叉项参数全部为0时退化为普通的线性模型。由于实际场景中，数据往往非常稀疏，因此对于二次项参数的训练是很困难的。因为对于每个参数<span>$w_{i,j}$</span><!-- Has MathJax -->需要大量的<span>$x_{i}$</span><!-- Has MathJax -->和<span>$x_{j}$</span><!-- Has MathJax -->均不为0的样本进行训练，但由于往往样本比较稀疏，这很容易导致参数<span>$w_{i,j}$</span><!-- Has MathJax -->不准确，最终将严重影响模型的性能。解决这一问题的方法是给每个特征分量<span>$x_{i}$</span><!-- Has MathJax -->引入一个辅助向量<span>$v_{i}=(v_{1},v_{2},...,v_{k})$</span><!-- Has MathJax -->，然后利用<span>$v{i}*v{j}$</span><!-- Has MathJax -->对参数<span>$w_{i,j}$</span><!-- Has MathJax -->进行估计，如下图所示：</p>
<p><img src="/images/fmyl.png" alt="img"></p>
<h3 id="FM模型训练"><a href="#FM模型训练" class="headerlink" title="FM模型训练"></a>FM模型训练</h3><p><img src="/images/fmcompu.png" alt="img"></p>
<p>对于FM原始模型可以看到参数的复杂度是<span>$O(n^2)$</span><!-- Has MathJax -->的，那么如何降低这一复杂度呢？可以通过下面的过程进行化简：</p>
<p><img src="/images/fmpro.png" alt="img"></p>
<p>化简后的参数复杂度为<span>$O(n)$</span><!-- Has MathJax -->，降低至线性复杂度：</p>
<p><img src="/images/fmtrans.png" alt="img"></p>
<p><strong>FM模型训练：</strong></p>
<p>采用随机梯度下降：</p>
<p><img src="/images/fmtrain.png" alt="img"></p>
<p><strong>FM模型特征工程：</strong></p>
<p><img src="/images/fmtzgc.png" alt="img"></p>
<h3 id="FM模型应用"><a href="#FM模型应用" class="headerlink" title="FM模型应用"></a>FM模型应用</h3><p>FM模型可应用于回归、分类和排名任务中，参考原论文中的应用方式：</p>
<p><img src="/images/fmapply.png" alt="img"></p>
<p><strong>回归任务可使用平方误差损失函数：</strong></p>
<span>$$\begin{gather*}

\text {Loss}=\frac{1}{2} \sum_{i=1}^{n}\left(\hat{y}_{i}-y_{i}\right)^{2}

\end{gather*}$$</span><!-- Has MathJax --> 
<p>求偏导，得到：</p>
<span>$$\begin{gather*}

\frac{\partial L}{\partial \hat{y}(x)}=(\hat{y}(x)-y)

\end{gather*}$$</span><!-- Has MathJax --> 
<p>则梯度为：</p>
<span>$$\begin{gather*}

\frac{\partial L}{\partial \theta}=(\hat{y}(x)-y) * \frac{\partial \hat{y}(x)}{\partial \theta}

\end{gather*}$$</span><!-- Has MathJax --> 
<p><strong>分类任务可使用对数损失函数：</strong></p>
<span>$$\begin{gather*}

\text { Loss }=\frac{1}{2} \sum_{i=1}^{n}-\ln \left(\sigma\left(\hat{y}_{i} y_{i}\right)\right)^{2}

\end{gather*}$$</span><!-- Has MathJax --> 
<p>其中：</p>
<span>$$\begin{gather*}

\sigma(\hat{y} y)=\frac{1}{1+e^{-\hat{y} y}}

\frac{\partial(\sigma(\hat{y} y))}{\partial \hat{y}}=\sigma(\hat{y} y) *[1-\sigma(\hat{y} y)] * y

\end{gather*}$$</span><!-- Has MathJax --> 
<p>对数损失函数的梯度为：</p>
<span>$$\begin{gather*}

\begin{array}{c}
\frac{\partial L}{\partial \theta}=\frac{1}{\sigma(\hat{y} y)} * \sigma(\hat{y} y) *\left[1-\sigma(\hat{y} y] * y * \frac{\partial \hat{y}(x)}{\partial \theta}\right. \\
=[1-\sigma(\hat{y} y)] * y * \frac{\partial \hat{y}(x)}{\partial \theta}
\end{array}

\end{gather*}$$</span><!-- Has MathJax --> 
<p><strong>排序任务</strong>可先利用FM模型获得分数，然后利用pairwise分类损失函数进行训练，当然也有多种求解方式，可参考<a href="http://octopuscoder.github.io/2020/01/19/搜索排序算法/" target="_blank" rel="external">搜索排序算法</a>。</p>
<h3 id="FM模型扩展知识点"><a href="#FM模型扩展知识点" class="headerlink" title="FM模型扩展知识点"></a>FM模型扩展知识点</h3><p><strong>FM模型优点：</strong></p>
<p>适用于数据稀疏场景。</p>
<p><img src="/images/fmyd.png" alt="img"></p>
<p><strong>线性回归 vs FM：</strong></p>
<p><img src="/images/lirvsfm.png" alt="img"></p>
<p><strong>FM模型演化：</strong></p>
<p><img src="/images/fmhis.png" alt="img"></p>
<p>FFM(Field Factorization Machine)是在FM的基础上引入了“场（Field）”的概念而形成的新模型。在FM中计算特征<span>$x_i$</span><!-- Has MathJax --> 与其他特征的交叉影响时，使用的都是同一个隐向量 <span>$V_i$</span><!-- Has MathJax --> 。而FFM将特征按照事先的规则分为多个场(Field)，特征 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 属于某个特定的场f。每个特征将被映射为多个隐向量 <span>$V_{i 1}, \ldots, V_{i f}$</span><!-- Has MathJax -->  ，每个隐向量对应一个场。当两个特征<span>$x_i,x_j$</span><!-- Has MathJax -->  ,组合时，用对方对应的场对应的隐向量做内积:<span>$w_{i j}=\mathbf{v}_{i, f_{j}}^{T} \mathbf{v}_{j, f_{i}}$</span><!-- Has MathJax --> </p>
<p>FFM 由于引入了场，使得每两组特征交叉的隐向量都是独立的，可以取得更好的组合效果， FM 可以看做只有一个场的 FFM。</p>
<p>DeepFM模型将深度神经网络模型与FM模型结合，模型结构如下图所示：</p>
<p><img src="/images/deepfm.png" alt="img"></p>
<p>模型分为两部分：FM（左边）和DNN（右边）：</p>
<ol>
<li>首先利用FM进行embedding得到Dense Embeddings的输出;</li>
<li>将Dense Embeddings的结果作为左边FM模型和右边DNN模型的输入。通过一定方式组合后，模型左边FM模块的输出完全模拟出了FM的效果，而右边的DNN模块则学到了比FM模块更高阶的交叉特征。</li>
<li>最后将DNN和FM的结果组合后输出。</li>
</ol>
<h2 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h2><p>关于GBDT已在<a href="http://octopuscoder.github.io/2020/03/27/LambdaMART从放弃到入门/" target="_blank" rel="external">LambdaMART从放弃到入门</a>一文中进行了介绍，具体可参考其中MART部分对于BT和GBT的介绍，本文只提取一些要点。理解GBDT要从决策树DT开始，然后是BT，再到GBT。梯度提升树BT用于分类模型时，是<strong>梯度提升决策树<code>GBDT</code></strong>；用于回归模型时，是<strong>梯度提升回归树<code>GBRT</code>，</strong>二者的区别主要是损失函数不同。李航老师在《统计学习方法》一书中对决策树的基础和原理进行了详细介绍，网上也有不少笔记资料，例如<a href="https://blog.csdn.net/john_hongming/article/details/89453626" target="_blank" rel="external">李航统计学习方法-决策树</a>。这里做一下简单总结：</p>
<ul>
<li><p>决策树通常包含三个步骤：特征选择、自顶向下生成和自底向上剪枝；</p>
</li>
<li><p>决策树通常分为三种，如下图所示：</p>
</li>
</ul>
<p><img src="/images/dt.png" alt="img"></p>
<blockquote>
<p>图片来自：<a href="https://zhuanlan.zhihu.com/p/121889349" target="_blank" rel="external">《统计学习方法》（第五章）决策树</a></p>
</blockquote>
<p>BT(Boosting Tree)提升树是以<strong>决策树</strong>为基本学习器的提升方法，它被认为是统计学习中性能最好的方法之一。提升树模型可以表示为决策树为基学习器的加法模型，其学习思想有点类似一打高尔夫球，先粗略的打一杆，然后在之前的基础上逐步靠近球洞，也就是说<strong>每一棵树学习的是之前所有树预测值和的残差</strong>，这个<strong>残差</strong>就是一个加预测值后得到真实值的累加量。不同问题的提升树学习算法主要区别在于使用的损失函数不同，（设预测值为<span>$\tilde{y}$</span><!-- Has MathJax --> ，真实值为<span>$\hat{y}$</span><!-- Has MathJax -->):</p>
<ul>
<li>回归问题：通常使用平方误差损失函数<span>$L(\tilde{y}, \hat{y})=(\tilde{y}-\hat{y})^{2}$</span><!-- Has MathJax -->。</li>
<li>分类问题：通常使用指数损失函数：<span>$L(\tilde{y}, \hat{y})=e^{-\tilde{y} \hat{y}}$</span><!-- Has MathJax --></li>
</ul>
<p>而当损失函数不是平方损失函数或指数损失函数时，由于求导复杂，导致每一步优化非常麻烦。针对这个问题，<code>Freidman</code>提出了<strong>梯度提升树算法(GBT)</strong>，其核心思想是<strong>利用损失函数的负梯度在当前模型的值作为残差的近似值</strong>，本质上是<strong>对损失函数进行一阶泰勒展开</strong>，从而拟合一个回归树。</p>
<p>XGBoost是对GBDT的进一步优化，主要改进点在于对损失函数进行二阶泰勒展开、加入正则化项和并行化处理等方面。</p>
<p><strong>XGBoost优缺点：</strong></p>
<p><img src="/images/xgyqd.png" alt="img"></p>
<p><strong>XGBoost vs GBDT:</strong></p>
<p><img src="/images/xgvsgb.png" alt="img"></p>
<p><strong>XGBoost相关论文：</strong></p>
<p><img src="/images/xgbhis.png" alt="img"></p>
<h2 id="Wide-amp-Deep"><a href="#Wide-amp-Deep" class="headerlink" title="Wide&amp;Deep"></a>Wide&amp;Deep</h2><p>W&amp;D模型由谷歌在DLRS 2016会议上提出，其核心思想是结合线性模型的记忆能力和深度模型的泛化能力，从而提升整体性能。记忆能力是指模型直接从历史数据中发现相关性，学习规则的能力，泛化能力指相关性的传递，即模型可以发现在历史数据中很少或者没有出现的特征组合、相关性。以点外卖为例，记忆能力可以推荐我们点过的外卖，或者与点过外卖强相关的外卖（类似商家、同样菜系），而泛化能力可以增加口味的多样性，例如每次都推煲仔饭也总有吃够的时候，泛化能力可以提供一些其他选择，例如烤鱼什么的。</p>
<h3 id="模型原理"><a href="#模型原理" class="headerlink" title="模型原理"></a>模型原理</h3><p>谷歌提出的Wide&amp;Deep模型中Wide部分使用广义线性模型LR，Deep部分使用深度神经网络DNN，值得注意的是Wide&amp;Deep不仅仅可以当做一个模型，而是可以作为一个推荐模型的框架，如本文开头的常见推荐模型图所示，我们可以对Wide和Deep部分进行改进。</p>
<p>谷歌提出的W&amp;D模型如下图所示：</p>
<p><img src="/images/wdmodel.png" alt="img"></p>
<p>Wide部分使用广义线性模型：<span>$y=\boldsymbol{w}^{T}[\boldsymbol{x}, \phi(\boldsymbol{x})]+b$</span><!-- Has MathJax --> </p>
<p>其中x表示原始特征，<span>$\phi(\boldsymbol{x})$</span><!-- Has MathJax --> 表示交叉特征。交叉特征定义为：<span>$\phi_{k}(\mathbf{x})=\prod_{i=1}^{d} x_{i}^{c_{k i}} \quad c_{k i} \in\{0,1\}$</span><!-- Has MathJax --> </p>
<span>$c_{k i}$</span><!-- Has MathJax --> 是一个布尔变量，当第i个特征是第k个变化的一部分时取1。对于二值特征，组合后的特征当且仅当原特征都为1时取1，这为广义线性模型增加了非线性能力。<br><br>Deep部分使用前馈神经网络：<span>$\boldsymbol{a}^{l+1}=f\left(\boldsymbol{W}^{l} \boldsymbol{a}^{l}+\boldsymbol{b}^{l}\right)$</span><!-- Has MathJax -->
<p>其中<span>$\boldsymbol{a}^{l}, \boldsymbol{b}^{l}, \boldsymbol{W}^{l}$</span><!-- Has MathJax -->分别表示第l层的激活值、偏置和权重，f是激活函数。</p>
<p>模型最终输出为：</p>
<span>$$\begin{gather*}

P(Y=1 \mid \mathbf{x})=\sigma\left(\mathbf{w}_{\text {wide }}^{T}[\mathbf{x}, \phi(\mathbf{x})]+\mathbf{w}_{\text {deep }}^{T} a^{\left(l_{f}\right)}+b\right)

\end{gather*}$$</span><!-- Has MathJax -->
<p>其中Y表示分类标签，<span>$\sigma(.)$</span><!-- Has MathJax -->是sigmoid函数，<span>$\phi(x)$</span><!-- Has MathJax -->是原始特征x的跨产品变换，b是偏置项， <span>$w_wide$</span><!-- Has MathJax -->是wide模型的权重向量， <span>$w_deep$</span><!-- Has MathJax -->是用于最终激活函数 <span>$a^(lf)$</span><!-- Has MathJax -->的权重。</p>
<p>损失函数选取logistic loss，也就是经常使用的交叉熵损失函数。</p>
<h3 id="模型特征"><a href="#模型特征" class="headerlink" title="模型特征"></a>模型特征</h3><p>谷歌将模型应用于Google Play商店的APP推荐，使用了年龄、已下载APP和设备类型等特征。注意Wide部分选择了记忆用户已安装的APP与被曝光APP之前的相关性，旨在推荐一些强相关的APP，可以理解为用户装了某个APP后还会装什么，例如安装了淘宝后推荐天猫、拼多多。</p>
<p><img src="/images/wdfeature.jpg" alt="img"></p>
<h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p>Wide部分使用带L1正则化的FTRL（Followed the Regularized Leader）算法进行训练，FTRL扩展阅读</p>
<blockquote>
<p><a href="https://link.zhihu.com/?target=https%3A//github.com/wzhe06/Ad-papers/blob/master/Optimization%2520Method/%25E5%259C%25A8%25E7%25BA%25BF%25E6%259C%2580%25E4%25BC%2598%25E5%258C%2596%25E6%25B1%2582%25E8%25A7%25A3%2528Online%2520Optimization%2529-%25E5%2586%25AF%25E6%2589%25AC.pdf" target="_blank" rel="external">在线优化求解</a></p>
</blockquote>
<p>FTRL是一种在线学习算法，可简单理解为一个稀疏性较好、精度不错的随机梯度下降算法，由于是随机梯度下降，因此可以在获取新的样本后进行训练，从而实现模型在线更新。那么Wide部分为何要注重正则化呢？上面模型特征部分已经提到，Wide部分使用的交叉特征是用户已安装APP和当前曝光APP，当两个ID类特征进行组合时，会产生维度爆炸的问题，并且会让原本已经十分稀疏的特征更加稀疏，所以需要利用正则化对海量特征进行过滤方便线上部署。</p>
<p>Deep部分使用常用的AdaGrad算法进行训练，由于输入已经是Age、#App Installs这些数值类特征，或者稠密化的Embedding向量，因此Deep部分不会存在很严重的特征稀疏问题。</p>
<h2 id="DIN"><a href="#DIN" class="headerlink" title="DIN"></a>DIN</h2><p>DIN模型在KDD 2018会议上提出，其核心是利用一个局部激活单元来更好的表征用户信息，增强用户信息与候选广告的相关性，这与在CV和NLP领域得到广泛应用的Attention思想其实是一致的。就Wide&amp;Deep框架来看，DIN模型是对于Deep部分的改进，我们先看一下Base Model：</p>
<p><img src="/images/din-base.png" alt="img"></p>
<h3 id="Base-Model"><a href="#Base-Model" class="headerlink" title="Base Model"></a>Base Model</h3><p>Base Model采用深度模型常见的Embedding+MLP方案，首先将大规模稀疏特征映射为Embedding向量，然后利用sum pooling转换为固定长度的向量，最后进行拼接输入到MLP学习特征与预测结果之间的关系，损失函数采用交叉熵损失函数。该模型的缺陷在于无法表达用户兴趣的多样性，因为对于不同的候选广告，模型都将用户的信息表征为一个固定向量，但对于某个候选广告，用户历史行为对于是否点击该广告的影响力一般是不一样的。例如用户历史行为中包含购买电脑、外套和篮球等信息，对于当前的鼠标广告，显然历史行为中的电脑购买信息影响力更大。显然我们可以利用Attention机制对用户侧信息进行更准确的表征，利用候选广告与用户行为的关系计算权重，辅助特征与结果的相关性学习，最终提高模型性能。</p>
<h3 id="DIN-Model"><a href="#DIN-Model" class="headerlink" title="DIN Model"></a>DIN Model</h3><p>DIN模型引入了一个设计的局部激活单元，作用是计算候选广告与用户各行为的权重，在给定候选广告A的基础上自适应地的计算用户信息的表示：</p>
<span>$$\boldsymbol{v}_{U}(A)=f\left(\boldsymbol{v}_{A}, \boldsymbol{e}_{1}, \boldsymbol{e}_{2}, \ldots, \boldsymbol{e}_{H}\right)=\sum_{j=1}^{H} a\left(\boldsymbol{e}_{j}, \boldsymbol{v}_{A}\right) \boldsymbol{e}_{j}=\sum_{j=1}^{H} \boldsymbol{w}_{j} \boldsymbol{e}_{j}$$</span><!-- Has MathJax --> 
<p>其中<span>$\left\{e_{1}, e 2, \ldots e H\right\}$</span><!-- Has MathJax --> 表示用户向量，<span>$v_{A}$</span><!-- Has MathJax --> 表示候选广告向量，<span>$a(\cdot)$</span><!-- Has MathJax -->表示前向传播网络。不同于Attention机制的是，<span>$\sum_{i} w_{i}=1$</span><!-- Has MathJax --> 的约束被放宽，因此输出权重的softmax归一化也不再采用，目的是表征更强烈的用户兴趣。</p>
<p><img src="/images/din.png" alt="img"></p>
<p>对于用户行为的序列特征，不免不产生一个想法，使用RNN、LSTM等建模会有助于提升效果吗？作者也利用LSTM模型进行了尝试，但是由于用户历史行为序列可能包含了多个并发的兴趣，不同兴趣点的快速跳跃和突然终结也会使用户行为的序列特征显得杂乱无章，但是一个可研究的方向。</p>
<h3 id="训练技巧"><a href="#训练技巧" class="headerlink" title="训练技巧"></a>训练技巧</h3><ol>
<li><p>Mini-batch Aware Regularization。正则化可以防止模型过拟合，但对于工业数据集来说，直接应用传统的正则化方法是不实际的，因为具有大规模稀疏输入和海量的参数。作者提出了一种有效的小批量处理感知型正则化器，它仅针对每个微型批处理中出现的稀疏特征的参数计算L2-范数。</p>
</li>
<li><p>Data Adaptive Activation Function。PRelu是常用的激活函数，采用值为0的硬修正点：</p>
<span>$$f(s)=\left\{\begin{array}{ll}
   s &amp; \text { if } s&gt;0 \\
   \alpha s &amp; \text { if } s \leq 0
   \end{array}=p(s) \cdot s+(1-p(s)) \cdot \alpha s\right.$$</span><!-- Has MathJax --> 
<p>当每层的输入遵循不同分布时，这可能不适合。作者设计了一个新的激活函数Dice：</p>
<span>$$\begin{gather*}

f(s)=p(s) \cdot s+(1-p(s)) \cdot \alpha s, p(s)=\frac{1}{1+e^{-\frac{s-E[s]}{\sqrt{\operatorname{var}[s]+\epsilon}}}}

\end{gather*}$$</span><!-- Has MathJax -->
<p>其中E[s]和Var[s]分别表示均值和方差，<span>$\epsilon$</span><!-- Has MathJax -->是一个常量，值为<span>$10^-8$</span><!-- Has MathJax --> 。Dice的关键思想是根据输入数据的分布来自适应地调整修正点，其值设置为输入的平均值。当<span>$E[s]=0,Var[s]=0$</span><!-- Has MathJax -->则退化为PRelu。</p>
<p>两个函数图像如下图所示：</p>
</li>
</ol>
<p><img src="/images/preludice.png" alt="img"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>回顾一下文章开头展示的常用推荐模型，我们以Wide&amp;Deep模型为中心进行梳理，本文介绍的LR、FM和GBDT属于Wide部分，而DIN则属于Deep部分。</p>
<p><img src="/images/rec1.jpg" alt=""></p>
<p>那么从Wide模型到Deep模型的迭代过程大致是什么样的，各个模型有何优缺点呢？这里引用<a href="http://octopuscoder.github.io/2020/01/19/%E6%90%9C%E7%B4%A2%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/" target="_blank" rel="external">搜索排序算法</a>一文的图片：</p>
<p><img width="700" src="/images/search_process.png"></p>
<p>从迭代过程看，模型特征表征能力逐渐增强，复杂度逐渐变高。值得注意的是由于深度模型十分复杂，可解释性很差，所以Wide模型在特定场景下是有用武之地的。例如谷歌论文里Wide部分用于APP的初始推荐，搜索排序系统中的时效模型，Wide模型适用于明确规则、便于人工干预的场景。近些年来的研究主要集中在Deep部分，开始应用Attention机制、GRU等在CV和NLP领域常用的技术。但在工业界，LR、GBDT目前还是在广泛使用，因为深度模型的训练和上线部署都比较复杂，如果效果没有得到显著提升，使用深度模型的性价比不高。所以需要针对特定场景和数据进行仔细分析，选择合适的模型。</p>
<h1 id="开源代码"><a href="#开源代码" class="headerlink" title="开源代码"></a>开源代码</h1><p>LR:  <a href="https://github.com/scikit-learn/scikit-learn/blob/master/examples/linear_model/plot_iris_logistic.py" target="_blank" rel="external">https://github.com/scikit-learn/scikit-learn/blob/master/examples/linear_model/plot_iris_logistic.py</a></p>
<p>GBDT、XGBoost: <a href="https://github.com/dmlc/xgboost" target="_blank" rel="external">https://github.com/dmlc/xgboost</a></p>
<p>FM:  <a href="https://github.com/srendle/libfm" target="_blank" rel="external">https://github.com/srendle/libfm</a></p>
<p>Wide&amp;Deep: <a href="https://github.com/Lapis-Hong/wide_deep" target="_blank" rel="external">https://github.com/Lapis-Hong/wide_deep</a></p>
<p>DIN: <a href="https://github.com/zhougr1993/DeepInterestNetwork" target="_blank" rel="external">https://github.com/zhougr1993/DeepInterestNetwork</a></p>
<h1 id="模型论文"><a href="#模型论文" class="headerlink" title="模型论文"></a>模型论文</h1><p>LR: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/predictingclicks.pdf" target="_blank" rel="external">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/predictingclicks.pdf</a></p>
<p>FM: <a href="https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf" target="_blank" rel="external">https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf</a></p>
<p>GBDT: <a href="https://projecteuclid.org/download/pdf_1/euclid.aos/1013203451" target="_blank" rel="external">https://projecteuclid.org/download/pdf_1/euclid.aos/1013203451</a></p>
<p>XGBoost: <a href="http://dmlc.cs.washington.edu/data/pdf/XGBoostArxiv.pdf" target="_blank" rel="external">http://dmlc.cs.washington.edu/data/pdf/XGBoostArxiv.pdf</a></p>
<p>Wide&amp;Deep: <a href="https://arxiv.org/pdf/1606.07792.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1606.07792.pdf</a></p>
<p>DIN: <a href="https://arxiv.org/pdf/1706.06978.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1706.06978.pdf</a></p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://zhuanlan.zhihu.com/p/80887841" target="_blank" rel="external">线性回归模型的概念、原理、代码和应用</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/151036015" target="_blank" rel="external">LR逻辑回归模型的原理、推导、代码和应用</a></p>
<p><a href="https://www.cnblogs.com/XDU-Lakers/p/11853034.html" target="_blank" rel="external">线性模型之逻辑回归(LR)(原理、公式推导、模型对比、常见面试点)</a></p>
<p><a href="https://www.cnblogs.com/XDU-Lakers/p/11770642.html" target="_blank" rel="external">L0、L1、L2范数正则化</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/162001079" target="_blank" rel="external">XGBoost的原理、推导、代码和应用</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/145436595" target="_blank" rel="external">FM因子分解机模型的原理、推导、代码和应用</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/109980037" target="_blank" rel="external">一文读懂FM模型</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/58160982" target="_blank" rel="external">推荐系统召回四模型之：全能的FM模型</a></p>
<p><a href="https://blog.csdn.net/jgj123321/article/details/91571640" target="_blank" rel="external">极大似然估计原理解析</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/153500425" target="_blank" rel="external">推荐系统玩家 之 因子分解机FM（Factorization Machines）</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/61096338" target="_blank" rel="external">FM、FFM、DeepFM学习笔记</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/53361519" target="_blank" rel="external">详解 Wide &amp; Deep 结构背后的动机</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/132708525" target="_blank" rel="external">Wide&amp;Deep模型原理与实现</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/142958834" target="_blank" rel="external">见微知著，你真的搞懂Google的Wide&amp;Deep模型了吗？</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/145149051" target="_blank" rel="external">2018阿里CTR预估模型—DIN（深度兴趣网络），后附TF2.0复现代码</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/09/论文简读-Controlling-Fairness-and-Bias-in-Dynamic-Learning-to-Rank/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jeb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小菜鸡">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/10/09/论文简读-Controlling-Fairness-and-Bias-in-Dynamic-Learning-to-Rank/" itemprop="url">论文简读-Controlling Fairness and Bias in Dynamic Learning-to-Rank</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-10-09T12:20:05+08:00">
                2020-10-09
              </time>
            

            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本篇论文获得SIGIR 2020 Best Paper，旨在通过构建公平的无偏统计量，解决动态排序中的不公平问题。排序算法广泛应用于推荐和搜索场景，但目前的算法大多存在马太效应，例如热搜场景，排名越靠前被点击的概率也就越大，在一段时间内，越是靠前的文章就越会被人点击，然后其排名持续提升，而初始排在后面的文章由于没有得到公平曝光而逐渐无人问津。不过仅仅考虑热搜场景的话，这里的马太效应是符合要求的，但在其他排序场景中，就会存在一些问题，例如在购物场景下，初始排名靠后的商品由于无法得到充分曝光相对成交量很少，这对商家来说是难以接受的。</p>
<h2 id="曝光模型偏差"><a href="#曝光模型偏差" class="headerlink" title="曝光模型偏差"></a>曝光模型偏差</h2><p>以新闻网站动态排序文章为例，假设有六篇文章，且没有关于排名的信息，那么我们可能向第一个用户提供随机的排名。根据该用户的点击行为更新排名，类似的，根据后续的用户点击行为，持续更新排名。最后找到一个适合大多数用户的排名，如下图所示：</p>
<p><img src="/images/FairCo1.png" alt="calcos"></p>
<p>这种动态学习排序的方式存在两个问题：</p>
<ol>
<li>位置选择偏差。每篇文章的平均点击次数并不等于喜欢这篇文章用户数，因为位置越靠后，获得的用户注意力就越少，点击次数相应较少，如下图所示：</li>
</ol>
<p><img src="/images/FairCo1-p.png" alt="calcos"></p>
<p>​    这是一个“富者越富”的问题，上图中的文章4上升到顶部的机会显然低于从一开始就在顶部的文章。</p>
<ol>
<li><p>曝光分配不均。假设我们能够以某种方式计算出文章的真实相关性，仍然会存在问题。假设上文中提到的六篇文章属于<span>$G_{Left}$</span><!-- Has MathJax -->和<span>$G_{Right}$</span><!-- Has MathJax -->两组，即有两组用户分别喜欢对应的文章，如下图所示：</p>
<p><img src="/images/FairCo2.png" alt="calcos"></p>
<p>根据排序规则，由于喜欢Right组文章的用户更多，因此会把Right组的文章全部排在前面，这导致Left组文章无法得到公平曝光，而相应的Left组用户也开始不喜欢这个产品，导致用户流失。但喜欢两个组文章的用户数只有2%的差异，这显然是不合理的。</p>
</li>
</ol>
<p>那么公平的动态排序算法要具有两个性质：</p>
<ol>
<li><strong>无偏性</strong>。用来描述用户偏好的统计量是无偏的。</li>
<li><strong>公平性</strong>。算法可以根据相关性对曝光量进行公平的分配。</li>
</ol>
<h2 id="文章排序模型"><a href="#文章排序模型" class="headerlink" title="文章排序模型"></a>文章排序模型</h2><p>仍以文章排序模型为例，该模型存在Exposure Unfairness和Impact Unfairness，如下图所示：</p>
<p><img src="/images/FairCo3.png" alt="calcos"></p>
<h3 id="曝光"><a href="#曝光" class="headerlink" title="曝光"></a>曝光</h3><p>为保证文章得到公平曝光，我们希望单位相关度下的期望曝光是一致的，即曝光可以表示为相关度的函数：</p>
<span>$$\begin{gather*}
\operatorname{Exp}(G \mid x)=f(\operatorname{Rel}(G \mid x))
\end{gather*}$$</span><!-- Has MathJax -->
<p>从公平的角度，我们希望各组文章进行与其相关度成比例的曝光：</p>
<span>$$\begin{gather*}
\frac{\operatorname{Exp}\left(G_{0} \mid x\right)}{\operatorname{Exp}\left(G_{1} \mid x\right)}=\frac{\operatorname{Rel}\left(G_{0} \mid x\right)}{\operatorname{Rel}\left(G_{1} \mid x\right)}
\end{gather*}$$</span><!-- Has MathJax -->
<p>那么公平性的差异就是两组单位相关度曝光的差异：</p>
<span>$$\begin{gather*}
\begin{array}{l}
D^{E}\left(G_{0}, G_{1}\right) \\
=\left|\frac{E x p\left(G_{0} \mid x\right)}{\operatorname{Rel}\left(G_{0} \mid x\right)}-\frac{\operatorname{Exp}\left(G_{1} \mid x\right)}{\operatorname{Rel}\left(G_{1} \mid x\right)}\right|
\end{array}
\end{gather*}$$</span><!-- Has MathJax -->
<h3 id="影响力"><a href="#影响力" class="headerlink" title="影响力"></a>影响力</h3><p>类似于曝光，影响力也是相关度的函数，这里的影响力可以认为是预期点击率：</p>
<span>$$\begin{gather*}
\operatorname{Imp}(G \mid x)=f(\operatorname{Rel}(G \mid x))
\end{gather*}$$</span><!-- Has MathJax -->
<p>同样，影响力的差异定义为单位相关度的影响力：</p>
<span>$$\begin{gather*}
D^{I}\left(G_{0}, G_{1}\right)=\left|\frac{\operatorname{Imp}\left(G_{0} \mid x\right)}{\operatorname{Rel}\left(G_{0} \mid x\right)}-\frac{\operatorname{Imp}\left(G_{1} \mid x\right)}{\operatorname{Rel}\left(G_{1} \mid x\right)}\right|
\end{gather*}$$</span><!-- Has MathJax -->
<p>仍以文章排序为例，不妨设<span>$\text { Exposure }(j)=1 / \log (1+j)$</span><!-- Has MathJax -->，如下图所示，可以看到两个组仅仅2%的差异导致曝光和影响力均不公平。</p>
<p><img src="/images/FairCo4.png" alt="calcos"></p>
<h2 id="动态排序"><a href="#动态排序" class="headerlink" title="动态排序"></a>动态排序</h2><p>假设给定一批文章，x表示用户信息，r表示文章与用户的相关性，t表示时间，则特定时间用户信息表示为<span>$x_{t}$</span><!-- Has MathJax -->，特定时间相关性表示为<span>$r_{t}$</span><!-- Has MathJax -->，一般来说，<span>$x_{t}$</span><!-- Has MathJax -->是明确已知的，<span>$r_{t}$</span><!-- Has MathJax -->是隐性不可知的。现有一个排序规则<span>$&pi;_{t}$</span><!-- Has MathJax -->可以得到排序打分<span>$&delta;_{t}$</span><!-- Has MathJax -->，则利用这个排序方法可以获得用户的反馈<span>$c_{t}(d)$</span><!-- Has MathJax -->，例如可以用0和1表示是否点击，掌握用户的反馈后可以利用动态排序算法得到t+1时刻的排序规则<span>$&pi;_{t+1}$</span><!-- Has MathJax -->。</p>
<span>$c_{t}(d)$</span><!-- Has MathJax -->用于描述用户的偏好，如果以点击和未点击来判断的话，用户偏好与相关性的关系可以表示为：<br><span>$$\begin{gather*}
c_{t}(d)=\left\{\begin{array}{rr}
r_{t}(d), &amp; \text { if } e_{t}(d)=1 \\
0, &amp; \text { otherwise }
\end{array}\right.
\end{gather*}$$</span><!-- Has MathJax -->
<span>$e_{t}$</span><!-- Has MathJax -->表示该文章是否曝光（有机会经过用户偏好试探），当且仅当文章被曝光且被点击时，用户的偏好才能被记录。也就是说，<span>$c_{t}(d)$</span><!-- Has MathJax -->只能表达经过试探的文章的偏好，对于未经试探的文章，无法正确记录其偏好。因为当<span>$c_{t}(d)=0$</span><!-- Has MathJax -->时，无法判断是因为未曝光还是因为曝光但没有点击导致的0。随着时间推移，迭代轮数增多，这个错误会更加明显。<br><br><span>$e_{t}$</span><!-- Has MathJax -->也有问题，对于新的文章，由于无法知道用户对其偏好，因此要通过试探的方法获得。那么如何确定文章的曝光顺序呢？一般来说会按排序分数确定曝光位置，排在越前面，被曝光的概率就越大，即用排序打分来决定文章的曝光，也就是position bias：<br><br><span>$c_{t}(d)$</span><!-- Has MathJax -->用于描述用户的偏好，如果以点击和未点击来判断的话，用户偏好与相关性的关系可以表示为：<br><span>$$\begin{gather*}
e_{t}(d)=\sigma_{d}
\end{gather*}$$</span><!-- Has MathJax -->
<span>$\sigma_{t}$</span><!-- Has MathJax -->可以理解为排序的打分，例如预估CTR，由用户信息、文章和两者的相关性计算得到。假设不进行动态调整，那么排序逻辑可以表示为：<br><br><span>$$\begin{gather*}
\pi(x)=\operatorname{argsort}_{d \in D}[R(d \mid x)]
\end{gather*}$$</span><!-- Has MathJax -->
<p>根据用户X的特征计算用户与文章d的相关度，进而根据打分公式获得排序分数，决定展示给特定用户的顺序。相关度<span>$R(d|x)$</span><!-- Has MathJax -->也可以简化为<span>$R(d)$</span><!-- Has MathJax -->，即大部分用户对该文章的偏好，不考虑用户个性化偏好。如果要进行动态调整，那么<span>$R(d|x)$</span><!-- Has MathJax -->需要根据时间进行调整，其调整的依据就是<span>$c_{t}(d)$</span><!-- Has MathJax -->用户偏好。</p>
<h2 id="具体建模"><a href="#具体建模" class="headerlink" title="具体建模"></a>具体建模</h2><p>下面我们看一下论文中描述公平性和无偏性的方式：</p>
<h3 id="公平性"><a href="#公平性" class="headerlink" title="公平性"></a>公平性</h3><p>关注是否曝光和用户偏好两个变量。</p>
<p>是否曝光与排序打分、用户信息和相关性有关，其概率表示为：</p>
<span>$$\begin{gather*}
p_{t}(d)=P\left(e_{t}(d)=1 \mid \sigma_{t}, x_{t}, r_{t}\right)
\end{gather*}$$</span><!-- Has MathJax -->
<p>论文中将单个物料扩展为一组物料，使用组内所有物料的平均曝光度，其中<span>$G_i$</span><!-- Has MathJax -->表示第i组的物料。</p>
<p>对物料的偏好可以使用R(d)衡量，同样使用组内所有物料偏好的平均值：</p>
<span>$$\begin{gather*}
p_{t}(d)=P\left(e_{t}(d)=1 \mid \sigma_{t}, x_{t}, r_{t}\right)
\end{gather*}$$</span><!-- Has MathJax -->
<p>实现公平就是要消除差异，即各组单位相关度的曝光尽可能一致：</p>
<span>$$\begin{gather*}
D_{\tau}^{E}\left(G_{i}, G_{j}\right)=\frac{\frac{1}{\tau} \sum_{t=1}^{\tau} \operatorname{Exp}_{t}\left(G_{i}\right)}{\operatorname{Merit}\left(G_{i}\right)}-\frac{\frac{1}{\tau} \sum_{t=1}^{\tau} \operatorname{Exp}_{t}\left(G_{j}\right)}{\operatorname{Merit}\left(G_{j}\right)}
\end{gather*}$$</span><!-- Has MathJax -->
<p>影响力公平的实现方式类似：</p>
<span>$$\begin{gather*}
\begin{array}{c}
\operatorname{Imp}_{t}\left(G_{i}\right)=\frac{1}{\left|G_{i}\right|} \sum_{d \in G_{i}} c_{t}(d) \\
D_{\tau}^{E}\left(G_{i}, G_{j}\right)=\frac{\frac{1}{\tau} \sum_{t=1}^{\tau} \operatorname{Imp}_{t}\left(G_{i}\right)}{\operatorname{Merit}\left(G_{i}\right)}-\frac{\frac{1}{\tau} \sum_{t=1}^{\tau} \operatorname{Imp}_{t}\left(G_{j}\right)}{\operatorname{Merit}\left(G_{j}\right)}
\end{array}
\end{gather*}$$</span><!-- Has MathJax -->
<h3 id="无偏性"><a href="#无偏性" class="headerlink" title="无偏性"></a>无偏性</h3><p>再回顾一下无偏性的定义：用于描述用户偏好的统计量是无偏的。这里我们需要考虑无偏性的三个变量：</p>
<ol>
<li>位置偏差<span>$p_t$</span><!-- Has MathJax --></li>
<li>用户与物料的相关性<span>$R(d|x)$</span><!-- Has MathJax --></li>
<li>全局物料相关性<span>$R(d)$</span><!-- Has MathJax --></li>
</ol>
<span>$p_t$</span><!-- Has MathJax -->表示position bais，即由于排位导致的曝光度不同，排在越后面曝光概率越小。为尽可能缓解position bais，简单地，可以直接根据用户特征、物料特征和用户物料相关度进行打分来确定排序，进一步优化可以考虑加入更多的特征，如上下文特征等。<br><br><span>$R(d|x)$</span><!-- Has MathJax -->表示物料与用户的真实相关度，例如点击概率，而通常是无法直接观测到实际相关度<span>$r_t$</span><!-- Has MathJax -->的，只能观测到<span>$c_t$</span><!-- Has MathJax -->，即用户的点击情况。因此可以使用抽样和因果推断的方法。<br><br>抽样指通过多次尝试，借助<span>$c_t$</span><!-- Has MathJax -->的数学期望来估计<span>$r_t$</span><!-- Has MathJax -->。<br><br>关于因果推断，事件/变量之间的关系，最主要的有<strong>相关性</strong>和<strong>因果性</strong>。<br><br>- 相关性是指在<strong>观测</strong>到的数据分布中，X与Y相关，如果我们<strong>观测</strong>到X的分布，就可以推断出Y的分布<br>- 因果性是指在<strong>操作/改变</strong>X后，Y随着这种<strong>操作/改变</strong>也变化，则说明X是Y的因<code>cause</code><br><br>在常用的机器学习算法中，关注的是特征之间的相关性，而无法去识别特征之间的因果性，而很多时候<strong>在做决策与判断的时候，我们需要的是因果性</strong>。举个例子，我们会发现在学校中，近视的同学成绩更好。近视和成绩好之间有强相关性，但显然近视不是成绩好的原因。而我们想要提升学生成绩，自然需要找到因，否则就会通过给学生戴眼镜的方式来提高成绩。上面的例子是很明显地可以区分出相关与因果的，但是也有很多难以区分的，如经常喝葡萄酒的人寿命更长，是因为葡萄酒确实能延长寿命，还是因为能经常喝的人通常更富有，享有更好的医疗条件。<br><br>因果推断中估算平均处理效应的经典方法包括“倾向性得分匹配”（Propensity Score Matching）、“倾向性得分加权 “（Propensity Score Weighting）等，本文使用加权的方法。因果推断也是一个比较复杂的研究方向，可参考Yishi Lin的博客进行扩展阅读，链接为：<br><br>&gt; <a href="https://dango.rocks/blog/2019/08/18/Causal-Inference-Introduction3-Propensity-Score-Weighting/" target="_blank" rel="external">因果推断漫谈</a><br><br>本文估计<span>$R(d|x)$</span><!-- Has MathJax -->，即<span>$r_t$</span><!-- Has MathJax -->的思路大致是，通过多次尝试，借助<span>$c_t$</span><!-- Has MathJax -->的数学期望来求<span>$R(d|x)$</span><!-- Has MathJax -->，但<span>$c_t$</span><!-- Has MathJax -->是有偏的。因此我们要使<span>$c_t$</span><!-- Has MathJax -->无偏，然后求得<span>$R(d|x)$</span><!-- Has MathJax -->的无偏估计。<br><br>假设我们可以观测到真实的相关度标签<span>$\left(\mathbf{r}_{1}, \ldots, \mathbf{r}_{\tau}\right)$</span><!-- Has MathJax -->，一个简单的方法是基于神经网络构建一个回归模型<span>$\hat{R}^{\mathrm{w}}\left(d \mid \boldsymbol{x}_{t}\right)$</span><!-- Has MathJax -->，损失函数使用最小平方误差函数，其中<span>$w$</span><!-- Has MathJax -->表示该模型的参数：<br><br><span>$$\begin{gather*}
\mathcal{L}^{\mathbf{r}}(w)=\sum_{t=1}^{\tau} \sum_{d}\left(\mathbf{r}_{t}(d)-\hat{R}^{\mathrm{w}}\left(d \mid \boldsymbol{x}_{t}\right)\right)^{2}
\end{gather*}$$</span><!-- Has MathJax -->
<p>该函数的目标是使<span>$R(d|x_t)$</span><!-- Has MathJax -->与<span>$r_t(d)$</span><!-- Has MathJax -->尽可能接近。但由于<span>$\left(\mathbf{r}_{1}, \ldots, \mathbf{r}_{\tau}\right)$</span><!-- Has MathJax -->是无法获取的，所以定义一个近似相等的目标函数，使用有偏反馈<span>$\left(\mathbf{c}_{1}, \ldots, \mathbf{c}_{\tau}\right)$</span><!-- Has MathJax -->。新目标函数使用Inverse Propensity Score (IPS) weighting方法来纠正position bias，IPS方法是因果推断中的经典方法，详细资料可参考上文链接，新的目标函数表示为：</p>
<span>$$\begin{gather*}
\mathcal{L}^{\mathbf{c}}(w)=\sum_{t=1}^{\tau} \sum_{d} \hat{R}^{\mathrm{w}}\left(d \mid \boldsymbol{x}_{t}\right)^{2}+\frac{\mathbf{c}_{t}(d)}{\mathbf{p}_{t}(d)}\left(\mathbf{c}_{t}(d)-2 \hat{R}^{\mathrm{w}}\left(d \mid \boldsymbol{x}_{t}\right)\right)
\end{gather*}$$</span><!-- Has MathJax -->
<p>新模型中的回归模型表示为<span>$\hat{R}^{\operatorname{Reg}}\left(d \mid \boldsymbol{x}_{t}\right)$</span><!-- Has MathJax -->。上述目标函数是无偏的，那就是说它的期望应该等于<span>$\mathcal{L}^{\mathbf{r}}(w)$</span><!-- Has MathJax -->：</p>
<span>$$\begin{gather*}
\begin{aligned}
\mathbb{E}_{\mathbf{e}} &amp;\left[\mathcal{L}^{\mathbf{c}}(w)\right] \\
&amp;=\sum_{t=1}^{\tau} \sum_{d} \sum_{\mathbf{e}_{t}(d)}\left[\hat{R}^{\mathbf{w}}\left(d \mid \boldsymbol{x}_{t}\right)^{2}+\frac{\mathbf{c}_{t}(d)}{\mathbf{p}_{t}(d)}\left(\mathbf{c}_{t}(d)-2 \hat{R}^{\mathbf{w}}\left(d \mid \boldsymbol{x}_{t}\right)\right)\right] \mathrm{P}\left(\mathbf{e}_{t}(d) \mid \boldsymbol{\sigma}_{t}, \boldsymbol{x}_{t}\right) \\
&amp;=\sum_{t=1}^{\tau} \sum_{d} \hat{R}^{\mathrm{w}}\left(d \mid \boldsymbol{x}_{t}\right)^{2}+\frac{1}{\mathbf{p}_{t}(d)} \mathbf{r}_{t}(d)\left(\mathbf{r}_{t}(d)-2 \hat{R}^{\mathrm{w}}\left(d \mid \boldsymbol{x}_{t}\right)\right) \mathbf{p}_{t}(d) \\
&amp;=\sum_{t=1}^{\tau} \sum_{d} \hat{R}^{\mathrm{w}}\left(d \mid \boldsymbol{x}_{t}\right)^{2}+\mathbf{r}_{t}(d)^{2}-2 \mathbf{r}_{t}(d) \hat{R}^{\mathrm{w}}\left(d \mid \boldsymbol{x}_{t}\right) \\
&amp;=\sum_{t=1}^{\tau} \sum_{d}\left(\mathbf{r}_{t}(d)-\hat{R}^{\mathrm{w}}\left(d \mid \boldsymbol{x}_{t}\right)\right)^{2} \\
&amp;=\mathcal{L}^{\mathbf{r}}(w)
\end{aligned}
\end{gather*}$$</span><!-- Has MathJax -->
<p>其中<span>$\mathrm{P}\left(\mathbf{e}_{t}(d) \mid \boldsymbol{\sigma}_{t}, \boldsymbol{x}_{t}\right)$</span><!-- Has MathJax -->表示边缘曝光概率，在曝光模型中就是<span>$p_t(d)$</span><!-- Has MathJax -->。</p>
<p>最后是<span>$R(d|x)$</span><!-- Has MathJax -->的简化版本<span>$R(d)$</span><!-- Has MathJax -->的估计，其无偏估计为：</p>
<span>$$\begin{gather*}
\hat{R}^{\mathrm{IPS}}(d)=\frac{1}{\tau} \sum_{t=1}^{\tau} \frac{\mathbf{c}_{t}(d)}{\mathbf{p}_{t}(d)}
\end{gather*}$$</span><!-- Has MathJax -->
<p>只要倾向是从0开始有界的，该估计就是无偏的：</p>
<span>$$\begin{gather*}
\begin{aligned}
\mathbb{E}_{\mathbf{e}}\left[\hat{R}^{\mathrm{IP}}(d)\right] &amp;=\frac{1}{\tau} \sum_{t=1}^{\tau} \sum_{\mathbf{e}_{t}(d)} \frac{\mathbf{e}_{t}(d) \mathbf{r}_{t}(d)}{\mathbf{p}_{t}(d)} \mathrm{P}\left(\mathbf{e}_{t}(d) \mid \boldsymbol{\sigma}_{t}, \boldsymbol{x}_{t}\right) \\
&amp;=\frac{1}{\tau} \sum_{t=1}^{\tau} \frac{\mathbf{r}_{t}(d)}{\mathbf{p}_{t}(d)} \mathbf{p}_{t}(d) \\
&amp;=\frac{1}{\tau} \sum_{t=1}^{\tau} \mathbf{r}_{t}(d) \\
&amp;=R(d)
\end{aligned}
\end{gather*}$$</span><!-- Has MathJax -->
<h2 id="公平性的动态控制"><a href="#公平性的动态控制" class="headerlink" title="公平性的动态控制"></a>公平性的动态控制</h2><p>基于上述公平性衡量方法以及相关的无偏估计量，该文提出了FairCo算法，其思想来源于Proportional Controller，即比例控制器，其核心是为了在常态信号下控制特定信号而构建的一种模型。关于比例控制器，举例说明:</p>
<blockquote>
<p>假设有一个水缸，最终的控制目的是要保证水缸里的水位永远的维持在1米的高度。假设初试时刻，水缸里的水位是0.2米，那么当前时刻的水位和目标水位之间是存在一个误差的error，且error为0.8.这个时候，假设旁边站着一个人，这个人通过往缸里加水的方式来控制水位。如果单纯的用比例控制算法，就是指加入的水量u和误差error是成正比的。即<br>u=kp<em>error<br>假设kp取0.5，<br>那么t=1时（表示第1次加水，也就是第一次对系统施加控制），那么u=0.5</em>0.8=0.4，所以这一次加入的水量会使水位在0.2的基础上上升0.4，达到0.6.<br>接着，t=2时刻（第2次施加控制），当前水位是0.6，所以error是0.4。u=0.5*0.4=0.2，会使水位再次上升0.2，达到0.8.<br>如此这么循环下去，就是比例控制算法的运行方法。 </p>
</blockquote>
<p>当然上面的例子是存在一些问题的，例如如果水缸漏水怎么办？这也是PID控制算法要解决的问题，扩展阅读：</p>
<blockquote>
<p><a href="https://blog.csdn.net/qq_25352981/article/details/81007075" target="_blank" rel="external">一文读懂PID控制算法</a></p>
</blockquote>
<p>本文中的常态是根据用户的偏好对内容进行排序，需要控制的是不能让某个组的物料过多的出现，FairCo算法表示为：</p>
<span>$$\begin{gather*}
\text { FairCo: } \quad \boldsymbol{\sigma}_{\tau}=\underset{d \in \mathcal{D}}{\operatorname{argsort}}\left(\hat{R}(d \mid \boldsymbol{x})+\lambda \operatorname{err}_{\tau}(d)\right)
\end{gather*}$$</span><!-- Has MathJax -->
<p>可以看到，FairCo算法是基于修改后的相关度得分来对物料进行排序的，该分数是<span>$\hat{R}(d \mid \boldsymbol{x})$</span><!-- Has MathJax -->加上一个误差项<span>$\operatorname{err}_{\tau}(d)$</span><!-- Has MathJax -->，误差项乘以一个权重参数<span>$\lambda$</span><!-- Has MathJax -->作为最后用于排序的分数，其中误差项为：</p>
<span>$$\begin{gather*}
\operatorname{err}_{\tau}(d)=(\tau-1) \cdot \max _{G_{i}}\left(\hat{D}_{\tau-1}\left(G_{i}, G\right)\right)
\end{gather*}$$</span><!-- Has MathJax -->
<p>误差项表示上一个时刻，即<span>$\mathcal{T}-1$</span><!-- Has MathJax -->时刻物料d所在组与优势（曝光、影响力…）最大组之间的最大差距。对于优势最大的组，误差项对排序的提升帮助为0，而其他组的排序会得到相应提升。</p>
<p>文中证明了随着时间推移，即当<span>$\mathcal{T}$</span><!-- Has MathJax -->趋向于无穷大时，各个组的平均差距将趋于0，平均差距定义如下：</p>
<span>$$\begin{gather*}
\bar{D}_{\tau}=\frac{2}{m(m-1)} \sum_{i=0}^{m} \sum_{j=i+1}^{m}\left|D_{\tau}\left(G_{i}, G_{j}\right)\right|
\end{gather*}$$</span><!-- Has MathJax -->
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>文中使用了一个自己的示例进行模拟，用相关的IPS估计器来评估Fairco算法。首先，从广告中抽取新闻文章作为测试数据集，该数据集用两极化得分标记每个新来源。然后模拟访问这个网站的用户，这样每个用户都有一个相关的两极化得分和一个开放性参数。如下图所示：</p>
<p><img src="/images/FairCo5.png" alt="calcos"></p>
<p>用户与新闻文章的真实相关度是新闻文章的两极化得分和用户开放性参数的函数，其真实相关度分布服从伯努利分布：</p>
<span>$$\begin{gather*}
\mathbf{r}_{t}(d) \sim \text { Bernoulli }\left[p=\exp \left(\frac{-\left(\rho^{u_{t}}-\rho^{d}\right)^{2}}{2\left(o^{u_{t}}\right)^{2}}\right)\right]
\end{gather*}$$</span><!-- Has MathJax -->
<p>在第一个实验中对一些右偏向性用户进行模拟，右偏向性用户可以通过在G-right文章中引入点击来偏向排名。可以看到公平控制器Fairco能从最初的偏差中恢复过来，同时仍在学习相关度，如下图所示：</p>
<p><img src="/images/FairCo6.png" alt="calcos"></p>
<p>未经调整的排名算法很难打破最初少数用户造成的偏差，即使某些“富人”在一开始就有大量的领先优势，Fairco也能够将这种偏差减少到零，并将不公平性保持在较低水平。这就意味着最开始的“富人”是有破产的风险的，但是某些“富人”也可能会继续受用户“偏爱”而富下去。</p>
<p>如果我们改变左偏向性用户在用户群体中的比例，Fairco可以始终将不公平性保持在接近零的水平，同时在其中一个群体占多数的情况下以公平换取效用，如下图所示：</p>
<p><img src="/images/FairCo7.png" alt="calcos"></p>
<p>这也对应了文章开头举的一些例子，例如在热搜场景中，FairCo算法可能就不是很适合，因为类似场景是要强化“马太效应”的，而FairCo算法为了公平会牺牲一些效用。相反在商品推荐等场景中我们要关注公平性，这时FairCo算法可得到相应使用。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/27/LambdaMART从放弃到入门/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jeb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小菜鸡">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/03/27/LambdaMART从放弃到入门/" itemprop="url">LambdaMART从放弃到入门</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-03-27T11:53:17+08:00">
                2020-03-27
              </time>
            

            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p> <img src="/images/letfly.png" alt=""></p>
<p>这篇文章希望站着把三件事办了：</p>
<ol>
<li>理解Lambda；</li>
<li>理解MART；</li>
<li>理解LambdaMART。</li>
</ol>
<p><strong>【待进一步整理】</strong></p>
<h1 id="Lambda"><a href="#Lambda" class="headerlink" title="Lambda"></a>Lambda</h1><p>关于Lambda梯度要从RankNet说起，RankNet提出了一种概率损失函数来学习Ranking Function，并应用Ranking Function对文档进行排序。LambdaRank在RankNet的基础上引入评价指标Z （如NDCG、ERR等），其损失函数的梯度代表了文档下一次迭代优化的方向和强度，由于引入了IR评价指标，Lambda梯度更关注位置靠前的优质文档的排序位置的提升，有效的避免了下调位置靠前优质文档的位置这种情况的发生。LambdaRank相比RankNet的优势在于分解因式后训练速度变快，同时考虑了评价指标，直接对问题求解，效果更明显。 详细内容可以参考<a href="https://octopuscoder.github.io/2020/01/19/搜索排序算法/" target="_blank" rel="external">搜索排序算法</a>。</p>
<h1 id="MART"><a href="#MART" class="headerlink" title="MART"></a>MART</h1><p>MART(Multiple Additive Regression Tree)的另一个名字叫GBDT(Gradient Boosting Decision Tree)，理解GBDT要从BT开始。</p>
<h2 id="提升树"><a href="#提升树" class="headerlink" title="提升树"></a>提升树</h2><p>BT(Boosting Tree)提升树是以<strong>决策树</strong>为基本学习器的提升方法，它被认为是统计学习中性能最好的方法之一。对于分类问题，提升树的决策树是二叉决策树，对于回归问题，提升树中的决策是二叉回归树。</p>
<p>提升树模型可以表示为决策树为基学习器的加法模型：</p>
<span>$$\begin{gather*}
f(\overrightarrow{\mathbf{x}})=f_{M}(\overrightarrow{\mathbf{x}})=\sum_{m=1}^{M} h_{m}\left(\overrightarrow{\mathbf{x}} ; \Theta_{m}\right)
\end{gather*}$$</span><!-- Has MathJax -->
<p>其中<span>$h_{m}\left(\overrightarrow{\mathbf{x}} ; \Theta_{m}\right)$</span><!-- Has MathJax -->表示第m个决策树，<span>$\Theta_{m}$</span><!-- Has MathJax -->为第m个决策树的参数，M为决策树的数量。</p>
<p><strong>提升树</strong>采用<strong>前向分步算法</strong>:</p>
<ul>
<li>首先确定初始提升树<span>$f_{0}(\overrightarrow{\mathbf{x}})=0$</span><!-- Has MathJax -->。</li>
<li>第m步模型为：<span>$f_{m}(\overrightarrow{\mathbf{x}})=f_{m-1}(\overrightarrow{\mathbf{x}})+h_{m}\left(\overrightarrow{\mathbf{x}} ; \Theta_{m}\right)$</span><!-- Has MathJax -->，其中<span>$h_{m}(\cdot)$</span><!-- Has MathJax -->为待求的第m棵决策树。</li>
<li>通过经验风险极小化确定第m棵决策树的参数<span>$\Theta_{m}$: $\hat{\Theta}_{m}=\arg \min _{\Theta_{m}} \sum_{i=1}^{N} L\left(\bar{y}_{i}, f_{m}\left(\overrightarrow{\mathbf{x}}_{i}\right)\right)$</span><!-- Has MathJax -->。这里没有引入正则项，而XGBoost中引入了正则项。</li>
</ul>
<p>不同问题的提升树学习算法主要区别在于使用的损失函数不同，（设预测值为<span>$\tilde{y}$</span><!-- Has MathJax --> ，真实值为<span>$\hat{y}$</span><!-- Has MathJax -->):</p>
<ul>
<li>回归问题：通常使用平方误差损失函数<span>$L(\tilde{y}, \hat{y})=(\tilde{y}-\hat{y})^{2}$</span><!-- Has MathJax -->。</li>
<li>分类问题：通常使用指数损失函数：<span>$L(\tilde{y}, \hat{y})=e^{-\tilde{y} \hat{y}}$</span><!-- Has MathJax --></li>
</ul>
<p><strong>提升树</strong>的学习<strong>思想</strong>有点类似一打高尔夫球，先粗略的打一杆，然后在之前的基础上逐步靠近球洞，也就是说<strong>每一棵树学习的是之前所有树预测值和的残差</strong>，这个<strong>残差</strong>就是一个加预测值后得到真实值的累加量。</p>
<p>例如在回归问题中，提升树采用平方误差损失函数，此时：</p>
<span>$$\begin{gather*}
\begin{aligned}
L\left(\tilde{y}, f_{m}(\overrightarrow{\mathbf{x}})\right) &amp;=L\left(\tilde{y}, f_{m-1}(\overrightarrow{\mathbf{x}})+h_{m}\left(\overrightarrow{\mathbf{x}} ; \Theta_{m}\right)\right)
=\left(\tilde{y}-f_{m-1}(\overrightarrow{\mathbf{x}})-h_{m}\left(\overrightarrow{\mathbf{x}} ; \Theta_{m}\right)\right)^{2} &amp;=\left(r-h_{m}\left(\overrightarrow{\mathbf{x}} ; \Theta_{m}\right)\right)^{2}
\end{aligned}
\end{gather*}$$</span><!-- Has MathJax -->
<p>其中<span>$r=\tilde{y}-f_{m-1}(\overrightarrow{\mathbf{x}})$</span><!-- Has MathJax -->为当前模型拟合数据的残差。所以对回归问题的提升树算法，第m个决策树 <span>$h_{m}(\cdot)$</span><!-- Has MathJax -->只需要简单拟合当前模型的残差。</p>
<p>回归提升树算法如下：</p>
<p> <img src="/images/boostingTree.png" alt=""></p>
<h2 id="梯度提升树-GBT"><a href="#梯度提升树-GBT" class="headerlink" title="梯度提升树(GBT)"></a>梯度提升树(GBT)</h2><p>上面所讲的提升树中，当损失函数是<strong>平方损失函数</strong>和<strong>指数损失函数</strong>时，每一步优化都很简单。因为平方损失函数和指数损失函数的求导非常简单。当损失函数是一般函数时，往往每一步优化不是很容易。针对这个问题，<code>Freidman</code>提出了<strong>梯度提升树算法(GBT)</strong>。</p>
<blockquote>
<p> <strong>梯度提升树(GBT)</strong>的一个核心思想是<strong>利用损失函数的负梯度在当前模型的值作为残差的近似值</strong>，本质上是<strong>对损失函数进行一阶泰勒展开</strong>，从而拟合一个回归树。</p>
</blockquote>
<p><strong>如何理解用负梯度近似残差</strong></p>
<ol>
<li><p>在对目标函数进行优化时，负梯度往往是函数下降最快的方向，自然也是GBDT目标函数下降最快的方向，所以用梯度去拟合首先是没什么问题的（并不是拟合梯度，只是用梯度去拟合）；GBDT本来中的g代表gradient，本来就是用梯度拟合；</p>
</li>
<li><p>用残差去拟合，只是目标函数是均方误差的一种特殊情况，CART中采用均方误差，符合这种情况。</p>
</li>
<li><p>为什么不直接使用残差拟合？目标函数除了loss可能还有正则项，正则中有参数和变量，很多情况下只拟合残差loss变小但是正则变大，目标函数不一定就小，这时候就要用梯度了，梯度的本质也是一种方向导数，综合了各个方向（参数）的变化，选择了一个总是最优（下降最快）的方向；</p>
</li>
</ol>
<p><strong>泰勒展开公式：</strong><br><span>$$\begin{gather*}
TaylorExpansion:f(x+\Delta x) \simeq f(x)+f^{\prime}(x) \Delta x+\frac{1}{2} f^{\prime \prime}(x) \Delta x^{2}
\end{gather*}$$</span><!-- Has MathJax --><br>将损失函数使用<strong>一阶泰勒展开公式</strong>(<span>$\Delta x$</span><!-- Has MathJax -->相当于这里的<span>$h_{m}\left(\overrightarrow{\mathbf{x}} ; \Theta_{m}\right))$</span><!-- Has MathJax -->：</p>
<span>$$\begin{gather*}
L\left(\tilde{y}, f_{m}(\overrightarrow{\mathrm{x}})\right)=L\left(\tilde{y}, f_{m-1}(\overrightarrow{\mathrm{x}})+h_{m}\left(\overrightarrow{\mathrm{x}} ; \Theta_{m}\right)\right)=L\left(\tilde{y}, f_{m-1}(\overrightarrow{\mathrm{x}})\right)+\frac{\partial L\left(\tilde{y}, f_{m-1}(\overrightarrow{\mathrm{x}})\right)}{\partial f_{m-1}(\overrightarrow{\mathrm{x}})} h_{m}\left(\overrightarrow{\mathrm{x}} ; \Theta_{m}\right)
\end{gather*}$$</span><!-- Has MathJax -->
<p>则有：</p>
<span>$$\begin{gather*}
\Delta L=L\left(\tilde{y}, f_{m}(\overrightarrow{\mathbf{x}})\right)-L\left(\tilde{y}, f_{m-1}(\overrightarrow{\mathbf{x}})\right)=\frac{\partial L\left(\tilde{y}, f_{m-1}(\overrightarrow{\mathbf{x}})\right)}{\partial f_{m-1}(\overrightarrow{\mathbf{x}})} h_{m}\left(\overrightarrow{\mathbf{x}} ; \Theta_{m}\right)
\end{gather*}$$</span><!-- Has MathJax -->
<p>要使得损失函数降低，则根据梯度下降的思想让损失函数对<span>$h_{m}\left(\overrightarrow{\mathbf{x}} ; \mathbf{\Theta}_{m}\right)$</span><!-- Has MathJax -->进行求导，按照负梯度更新该值，则损失函数是下降的，即：<span>$h_{m}\left(\overrightarrow{\mathbf{x}} ; \Theta_{m}\right)=-\frac{\partial L\left(\tilde{y}, f_{m-1}(\overrightarrow{\mathbf{x}})\right)}{\partial f_{m-1}(\overrightarrow{\mathbf{x}})}$</span><!-- Has MathJax --></p>
<p>这里进一步解释一下，对于函数f：<br><span>$$\begin{gather*}
f\left(\theta_{k+1}\right) \approx f\left(\theta_{k}\right)+\frac{\partial f\left(\theta_{k}\right)}{\partial \theta_{k}}\left(\theta_{k+1}-\theta_{k}\right)
\end{gather*}$$</span><!-- Has MathJax --><br>使用梯度下降算法时，<span>$\theta_{k+1}=\theta_{k+1}-\eta \frac{\partial f\left(\theta_{k}\right)}{\partial \theta_{k}}$</span><!-- Has MathJax -->。</p>
<p>而在GBDT中，我们对损失函数进行展开：<span>$L\left(y, f_{m}(x)\right) \approx L\left(y, f_{m-1}(x)\right)+\frac{\partial L\left(y, f_{m-1}(x)\right)}{\partial f_{m-1}(x)}\left(f_{m}(x)-f_{m-1}(x)\right)$</span><!-- Has MathJax --></p>
<p>即，<span>$L\left(y, f_{m}(x)\right) \approx L\left(y, f{m-1}(x)\right)+\frac{\partial L\left(y, f_{m-1}(x)\right)}{\partial f_{m-1}(x)} T_{m}(x)$</span><!-- Has MathJax --></p>
<p>在优化<span>$L(y, f(x))$</span><!-- Has MathJax -->时，应用梯度下降算法时，有：<span>$f_{m}(x)=f_{m-1}(x)-\eta \frac{\partial L\left(y, f_{m-1}(x)\right)}{\partial f_{m-1}(x)}$</span><!-- Has MathJax --></p>
<p>则有<span>$T_{m}(x)=-\eta \frac{\partial L\left(y, f{m-1}(x)\right)}{\partial f_{m-1}(x)}$</span><!-- Has MathJax --> ，即负梯度可以近似认为是残差，区别在于$\eta$。</p>
<ul>
<li>对于平方损失函数，它就是通常意义的残差。</li>
<li>对于一般损失函数，它就是残差的近似。</li>
</ul>
<p>这里我们相当于获得了样本的标签，接下来就是用这个标签来训练决策树。</p>
<p>另外，梯度提升树用于分类模型时，是<strong>梯度提升决策树<code>GBDT</code></strong>；用于回归模型时，是<strong>梯度提升回归树<code>GBRT</code>，</strong>二者的区别主要是损失函数不同。</p>
<p><strong>GBRT</strong>算法的伪代码如下：</p>
<p> <img src="/images/GBRT.png" alt=""></p>
<p>另外，Freidman从bagging策略受到启发，采用<strong>随机梯度提升</strong>来修改了原始的梯度提升算法，即每一轮迭代中，新的决策树拟合的是原始训练集的一个子集（而并不是原始训练集）的残差，这个子集是通过对原始训练集的无放回随机采样而来，类似于自助采样法。这种方法<strong>引入了随机性，有助于改善过拟合</strong>，另一个好处是<strong>未被采样的另一部分字集可以用来计算包外估计误差</strong>。</p>
<p>这时我们再看一下LambdaMART算法的流程：</p>
<p><img src="/images/LambdaMART2.png" alt=""></p>
<p>对比GBRT和LambdaMART算法流程可以发现两者非常相似，主要区别是LambdaMART将GBRT中要拟合的负梯度替换为Lambda梯度，而LambdaMART对排序的最核心的改进正是这个Lambda梯度，具体介绍可以参考<a href="[http://octopuscoder.github.io/2020/01/19/%E6%90%9C%E7%B4%A2%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/](http://octopuscoder.github.io/2020/01/19/搜索排序算法/">搜索排序算法</a>)中关于RankNet和LambdaRank的介绍。</p>
<h2 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h2><p>这里既然提到了提升树和梯度提升树，那么顺便也介绍一下大名鼎鼎的XGBoost，这部分介绍完后我们再探LambdaMART的一些细节。</p>
<p><strong>Xgboost</strong>也使用与提升树相同的<strong>前向分步算法，</strong>其区别在于：Xgboost通过<strong>结构风险最小化</strong>来确定下一个决策树的参数$\Theta_{m}$：</p>
<span>$\hat{\Theta}_{m}=\arg \min _{\Theta_{m}} \sum_{i=1}^{N} L\left(\tilde{y}_{i}, f_{m}\left(\overrightarrow{\mathbf{x}}_{i}\right)\right)+\Omega\left(h_{m}(\overrightarrow{\mathbf{x}})\right)$</span><!-- Has MathJax -->
<p>其中：</p>
<ul>
<li><span>$\Omega\left(h_{m}\right)$</span><!-- Has MathJax -->为第m个决策树的正则化项，这是XGBoost和GBT的一个重要区别。</li>
<li><span>$\mathcal{L}=\sum_{i=1}^{N} L\left(\tilde{y}_{i}, f_{m}\left(\overrightarrow{\mathbf{x}}_{i}\right)\right)+\Omega\left(h_{m}(\overrightarrow{\mathbf{x}})\right)$</span><!-- Has MathJax -->为目标函数。</li>
</ul>
<p>与提升树不同的是<strong>，Xgboost</strong>还使用了<strong>二阶泰勒展开</strong>，定义：</p>
<span>$\hat{y}_{i}^{&lt;m-1&gt;}=f_{m-1}\left(\overrightarrow{\mathbf{x}}_{i}\right), \quad g_{i}=\frac{\partial L\left(\tilde{y}_{i}, \hat{y}_{i}^{&lt;m-1&gt;}\right)}{\partial \hat{y}_{i}^{&lt;m-1&gt;}}, \quad h_{i}=\frac{\partial^{2} L\left(\tilde{y}_{i}, \hat{y}_{i}^{&lt;m-1&gt;}\right)}{\partial^{2} \hat{y}_{i}^{&lt;m-1&gt;}}$</span><!-- Has MathJax -->
<p>其中，<span>$g_{i}, h_{i}$</span><!-- Has MathJax -->分别是损失函数<span>$L\left(\tilde{y}_{i}, \hat{y}_{i}^{&lt;m-1&gt;}\right)$</span><!-- Has MathJax -->对<span>$\hat{y}_{i}^{&lt;m-1&gt;}$</span><!-- Has MathJax -->的一阶导数和二阶导数。再看<strong>泰勒展开式</strong>：</p>
<p>Taylor expansion <span>$f(x+\Delta x) \simeq f(x)+f^{\prime}(x) \Delta x+\frac{1}{2} f^{\prime \prime}(x) \Delta x^{2}$</span><!-- Has MathJax --></p>
<p>因此我们对损失函数二阶泰勒展开有（<span>$\Delta x$</span><!-- Has MathJax -->相当于这里的<span>$h_{m}(\overrightarrow{\mathbf{x}})$</span><!-- Has MathJax -->）</p>
<span>$$\begin{gather*}
\begin{aligned} \mathcal{L} &amp;=\sum_{i=1}^{N} L\left(\tilde{y}_{i}, f_{m}\left(\overrightarrow{\mathbf{x}}_{i}\right)\right)+\Omega\left(h_{m}(\overrightarrow{\mathbf{x}})\right)=\sum_{i=1}^{N} L\left(\tilde{y}_{i}, \hat{y}_{i}^{&lt;m-1&gt;}+h_{m}\left(\overrightarrow{\mathbf{x}}_{i}\right)\right)+\Omega\left(h_{m}(\overrightarrow{\mathbf{x}})\right) \\ &amp; \simeq \sum_{i=1}^{N}\left[L\left(\tilde{y}_{i}, \hat{y}_{i}^{&lt;m-1&gt;}\right)+g_{i} h_{m}\left(\overrightarrow{\mathbf{x}}_{i}\right)+\frac{1}{2} h_{i} h_{m}^{2}\left(\overrightarrow{\mathbf{x}}_{i}\right)\right]+\Omega\left(h_{m}(\overrightarrow{\mathbf{x}})\right)+\text { constant } \end{aligned}
\end{gather*}$$</span><!-- Has MathJax -->
<p><strong>提升树(GBT)</strong>只使用了一阶泰勒展开。而XGBoost的正则化项由两部分组成：<span>$\Omega\left(h_{m}(\overrightarrow{\mathbf{x}})\right)=\gamma T+\frac{1}{2} \lambda \sum_{j=1}^{T} w_{j}^{2}$</span><!-- Has MathJax --></p>
<p>该部分表示<strong>决策树的复杂度，</strong>其中T为叶节点的个数，$w_{j}$为每个叶节点的输出值，$\gamma, \lambda \geq 0$为系数，控制这两个部分的比重。</p>
<ul>
<li>叶结点越多，则决策树越复杂。</li>
<li>每个叶结点输出值的绝对值越大，则决策树越复杂。</li>
</ul>
<blockquote>
<p>该复杂度是一个经验公式。事实上还有很多其他的定义复杂度的方式，只是这个公式效果还不错。</p>
</blockquote>
<p><strong>Xgboost</strong>相比与<strong>GBDT</strong>：</p>
<ol>
<li><p>传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了<strong>二阶泰勒展开，同时用到了一阶和二阶导数</strong>。顺便提一下，xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。例如，xgboost支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）</p>
</li>
<li><p>xgboost在<strong>代价函数里加入了正则项，用于控制模型的复杂度</strong>。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。从Bias-variance tradeoff角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，这也是xgboost优于传统GBDT的一个特性。</p>
</li>
<li><p><strong>列抽样（column subsampling）</strong>。xgboost借鉴了随机森林的做法，支持列抽样（即每次的输入特征不是全部特征），不仅能降低过拟合，还能减少计算，这也是xgboost异于传统gbdt的一个特性。</p>
</li>
<li><p><strong>并行化处理</strong>：在训练之前，预先对每个特征内部进行了排序找出候选切割点，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行，即在不同的特征属性上采用多线程并行方式寻找最佳分割点。</p>
</li>
</ol>
<p><strong>相比于GBDT，Xgboost最重要的优点还是用到了二阶泰勒展开信息和加入正则项</strong> 。</p>
<h1 id="LambdaMART"><a href="#LambdaMART" class="headerlink" title="LambdaMART"></a>LambdaMART</h1><p>LambdaMART算法的流程：</p>
<p><img src="/images/LambdaMART2.png" alt=""></p>
<p>叶子结点输出值的计算采用牛顿迭代法，对于一个函数<span>$g(\gamma)$</span><!-- Has MathJax -->，为了找到$\gamma$使得函数$g$取得极小（大）值采用牛顿迭代法的迭代步骤为：</p>
<span>$$\begin{gather*}

\gamma_{n+1}=\gamma_{n}-\frac{g^{\prime}\left(\gamma_{n}\right)}{g^{\prime \prime}\left(\gamma_{n}\right)}

\end{gather*}$$</span><!-- Has MathJax -->
<p>相应地，LambdaMART第m棵树中第k个叶子结点的输出值计算公式为：</p>
<span>$$\begin{gather*}

\gamma_{k m}=\frac{\sum_{x_{i} \in R_{k m}} \frac{\partial C}{\partial s_{i}}}{\sum_{x_{i} \in R_{k m}} \frac{\partial^{2} C}{\partial s_{i}^{2}}}=\frac{-\sum_{x_{i} \in R_{k m}} \sum_{\{i, j\} \rightleftharpoons I}\left|\Delta Z_{i j}\right| \rho_{i j}}{\sum_{x_{i} \in R_{k m}} \sum_{\{i, j\} \rightleftharpoons I}\left|\Delta Z_{i j}\right| \sigma \rho_{i j}\left(1-\rho_{i j}\right)}

\end{gather*}$$</span><!-- Has MathJax -->
<p>具体原理可以参考<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf" target="_blank" rel="external">From RankNet to LambdaRank to LambdaMART: An Overview</a></p>
<p>下面我们基于Ranklib源码和一个具体的例子来进一步理解LambdaMART算法的过程。Ranklib是Learning to Rank领域的一个优秀的开源算法库，实现了MART,RankNet,RankBoost,LambdaMart,Random Forest等模型，代码为Java。我们这里基于微软发布的LambdaMART来进行介绍，LambdaMART.java中的LambdaMART.learn()是学习流程的管控函数，学习过程主要有下面四步构成：</p>
<ol>
<li><p>计算deltaNDCG以及lambda;</p>
</li>
<li><p>以lambda作为label训练一棵regression tree;</p>
</li>
<li><p>在tree的每个叶子节点通过预测的regression lambda值还原出gamma，即最终输出得分；</p>
</li>
<li><p>用3的模型预测所有训练集合上的得分（+learningRate*gamma）,然后用这个得分对每个query的结果排序，计算新的每个query的base ndcg，以此为基础回到第1步，组成森林。</p>
</li>
</ol>
<p>重复这个步骤，直到满足下列两个收敛条件之一：</p>
<ol>
<li><p>树的个数达到训练参数设置；</p>
</li>
<li><p>Random Forest在validation集合上没有变好。</p>
</li>
</ol>
<p>下面用一组实际的数据来说明整个计算过程，假设我们有10个query的训练数据，每个query下有10个doc，每个query-doc对有10个feature，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="number">0</span> qid:<span class="number">1830</span> <span class="number">1</span>:<span class="number">0.002736</span> <span class="number">2</span>:<span class="number">0.000000</span> <span class="number">3</span>:<span class="number">0.000000</span> <span class="number">4</span>:<span class="number">0.000000</span> <span class="number">5</span>:<span class="number">0.002736</span> <span class="number">6</span>:<span class="number">0.000000</span> <span class="number">7</span>:<span class="number">0.000000</span> <span class="number">8</span>:<span class="number">0.000000</span> <span class="number">9</span>:<span class="number">0.000000</span> <span class="number">10</span>:<span class="number">0.000000</span></div><div class="line"><span class="number">0</span> qid:<span class="number">1830</span> <span class="number">1</span>:<span class="number">0.025992</span> <span class="number">2</span>:<span class="number">0.125000</span> <span class="number">3</span>:<span class="number">0.000000</span> <span class="number">4</span>:<span class="number">0.000000</span> <span class="number">5</span>:<span class="number">0.027360</span> <span class="number">6</span>:<span class="number">0.000000</span> <span class="number">7</span>:<span class="number">0.000000</span> <span class="number">8</span>:<span class="number">0.000000</span> <span class="number">9</span>:<span class="number">0.000000</span> <span class="number">10</span>:<span class="number">0.000000</span></div><div class="line"><span class="number">0</span> qid:<span class="number">1830</span> <span class="number">1</span>:<span class="number">0.001368</span> <span class="number">2</span>:<span class="number">0.000000</span> <span class="number">3</span>:<span class="number">0.000000</span> <span class="number">4</span>:<span class="number">0.000000</span> <span class="number">5</span>:<span class="number">0.001368</span> <span class="number">6</span>:<span class="number">0.000000</span> <span class="number">7</span>:<span class="number">0.000000</span> <span class="number">8</span>:<span class="number">0.000000</span> <span class="number">9</span>:<span class="number">0.000000</span> <span class="number">10</span>:<span class="number">0.000000</span></div><div class="line"><span class="number">1</span> qid:<span class="number">1830</span> <span class="number">1</span>:<span class="number">0.188782</span> <span class="number">2</span>:<span class="number">0.375000</span> <span class="number">3</span>:<span class="number">0.333333</span> <span class="number">4</span>:<span class="number">1.000000</span> <span class="number">5</span>:<span class="number">0.195622</span> <span class="number">6</span>:<span class="number">0.000000</span> <span class="number">7</span>:<span class="number">0.000000</span> <span class="number">8</span>:<span class="number">0.000000</span> <span class="number">9</span>:<span class="number">0.000000</span> <span class="number">10</span>:<span class="number">0.000000</span></div><div class="line"><span class="number">1</span> qid:<span class="number">1830</span> <span class="number">1</span>:<span class="number">0.077975</span> <span class="number">2</span>:<span class="number">0.500000</span> <span class="number">3</span>:<span class="number">0.666667</span> <span class="number">4</span>:<span class="number">0.000000</span> <span class="number">5</span>:<span class="number">0.086183</span> <span class="number">6</span>:<span class="number">0.000000</span> <span class="number">7</span>:<span class="number">0.000000</span> <span class="number">8</span>:<span class="number">0.000000</span> <span class="number">9</span>:<span class="number">0.000000</span> <span class="number">10</span>:<span class="number">0.000000</span></div><div class="line"><span class="number">0</span> qid:<span class="number">1830</span> <span class="number">1</span>:<span class="number">0.075239</span> <span class="number">2</span>:<span class="number">0.125000</span> <span class="number">3</span>:<span class="number">0.333333</span> <span class="number">4</span>:<span class="number">0.000000</span> <span class="number">5</span>:<span class="number">0.077975</span> <span class="number">6</span>:<span class="number">0.000000</span> <span class="number">7</span>:<span class="number">0.000000</span> <span class="number">8</span>:<span class="number">0.000000</span> <span class="number">9</span>:<span class="number">0.000000</span> <span class="number">10</span>:<span class="number">0.000000</span></div><div class="line"><span class="number">1</span> qid:<span class="number">1830</span> <span class="number">1</span>:<span class="number">0.079343</span> <span class="number">2</span>:<span class="number">0.250000</span> <span class="number">3</span>:<span class="number">0.666667</span> <span class="number">4</span>:<span class="number">0.000000</span> <span class="number">5</span>:<span class="number">0.084815</span> <span class="number">6</span>:<span class="number">0.000000</span> <span class="number">7</span>:<span class="number">0.000000</span> <span class="number">8</span>:<span class="number">0.000000</span> <span class="number">9</span>:<span class="number">0.000000</span> <span class="number">10</span>:<span class="number">0.000000</span></div><div class="line"><span class="number">1</span> qid:<span class="number">1830</span> <span class="number">1</span>:<span class="number">0.147743</span> <span class="number">2</span>:<span class="number">0.000000</span> <span class="number">3</span>:<span class="number">0.000000</span> <span class="number">4</span>:<span class="number">0.000000</span> <span class="number">5</span>:<span class="number">0.147743</span> <span class="number">6</span>:<span class="number">0.000000</span> <span class="number">7</span>:<span class="number">0.000000</span> <span class="number">8</span>:<span class="number">0.000000</span> <span class="number">9</span>:<span class="number">0.000000</span> <span class="number">10</span>:<span class="number">0.000000</span></div><div class="line"><span class="number">0</span> qid:<span class="number">1830</span> <span class="number">1</span>:<span class="number">0.058824</span> <span class="number">2</span>:<span class="number">0.000000</span> <span class="number">3</span>:<span class="number">0.000000</span> <span class="number">4</span>:<span class="number">0.000000</span> <span class="number">5</span>:<span class="number">0.058824</span> <span class="number">6</span>:<span class="number">0.000000</span> <span class="number">7</span>:<span class="number">0.000000</span> <span class="number">8</span>:<span class="number">0.000000</span> <span class="number">9</span>:<span class="number">0.000000</span> <span class="number">10</span>:<span class="number">0.000000</span></div><div class="line"><span class="number">0</span> qid:<span class="number">1830</span> <span class="number">1</span>:<span class="number">0.071135</span> <span class="number">2</span>:<span class="number">0.125000</span> <span class="number">3</span>:<span class="number">0.333333</span> <span class="number">4</span>:<span class="number">0.000000</span> <span class="number">5</span>:<span class="number">0.073871</span> <span class="number">6</span>:<span class="number">0.000000</span> <span class="number">7</span>:<span class="number">0.000000</span> <span class="number">8</span>:<span class="number">0.000000</span> <span class="number">9</span>:<span class="number">0.000000</span> <span class="number">10</span>:<span class="number">0.000000</span></div><div class="line"><span class="number">1</span> qid:<span class="number">1840</span> <span class="number">1</span>:<span class="number">0.007364</span> <span class="number">2</span>:<span class="number">0.200000</span> <span class="number">3</span>:<span class="number">1.000000</span> <span class="number">4</span>:<span class="number">0.500000</span> <span class="number">5</span>:<span class="number">0.013158</span> <span class="number">6</span>:<span class="number">0.000000</span> <span class="number">7</span>:<span class="number">0.000000</span> <span class="number">8</span>:<span class="number">0.000000</span> <span class="number">9</span>:<span class="number">0.000000</span> <span class="number">10</span>:<span class="number">0.000000</span></div><div class="line"><span class="number">1</span> qid:<span class="number">1840</span> <span class="number">1</span>:<span class="number">0.097202</span> <span class="number">2</span>:<span class="number">0.000000</span> <span class="number">3</span>:<span class="number">0.000000</span> <span class="number">4</span>:<span class="number">0.000000</span> <span class="number">5</span>:<span class="number">0.096491</span> <span class="number">6</span>:<span class="number">0.000000</span> <span class="number">7</span>:<span class="number">0.000000</span> <span class="number">8</span>:<span class="number">0.000000</span> <span class="number">9</span>:<span class="number">0.000000</span> <span class="number">10</span>:<span class="number">0.000000</span></div><div class="line"><span class="number">2</span> qid:<span class="number">1840</span> <span class="number">1</span>:<span class="number">0.169367</span> <span class="number">2</span>:<span class="number">0.000000</span> <span class="number">3</span>:<span class="number">0.500000</span> <span class="number">4</span>:<span class="number">0.000000</span> <span class="number">5</span>:<span class="number">0.169591</span> <span class="number">6</span>:<span class="number">0.000000</span> <span class="number">7</span>:<span class="number">0.000000</span> <span class="number">8</span>:<span class="number">0.000000</span> <span class="number">9</span>:<span class="number">0.000000</span> <span class="number">10</span>:<span class="number">0.000000</span></div><div class="line">......</div></pre></td></tr></table></figure>
<p>为了简便，省略了余下的数据。上面的数据格式是按照Ranklib readme中要求的格式组织，除了行号之外，第一列是query-doc对的实际label（人工标注数据），第二列是qid，后面10列都是feature。</p>
<p>这份数据每组qid中的doc初始顺序可以是随机的，也可以是从实际的系统中获得的顺序，总之这个是计算ndcg的初始状态。对于qid=1830，它的10个doc的初始顺序的label序列是：0, 0, 0, 1, 1, 0, 1, 1, 0, 0(实际中label可以扩展为1，2，3，4等，根据数据自行决定)。dcg的计算公式为：</p>
<span>$$\begin{gather*}
dcg(i)=\frac{2^{l a b e l(i)}-1}{\log _{2}(i+1)}
\end{gather*}$$</span><!-- Has MathJax -->
<p>i表示当前doc在这个qid下的位置（从1开始，避免分母为0），label(i)是doc(i)的标注值。而一个query的dcg则是其下所有doc的加和：</p>
<span>$$\begin{gather*}
dcg(query)=\sum_{i} \frac{2^{l a b e l(i)}-1}{\log _{2}(i+1)}
\end{gather*}$$</span><!-- Has MathJax -->
<p>根据上式可以计算初始状态下每个qid的dcg：</p>
<span>$$\begin{gather*}

\begin{aligned} d c g(q i d=1830) &amp;=\frac{2^{0}-1}{\log _{2}(1+1)}+\frac{2^{0}-1}{\log _{2}(2+1)}+\ldots+\frac{2^{0}-1}{\log _{2}(10+1)} \\ &amp;=0+0+0+0.431+0.387+0+0.333+0.315+0 \\ &amp;+0=1.466 \end{aligned}
\end{gather*}$$</span><!-- Has MathJax -->
<p>要计算ndcg，还需要计算理想集的dcg，将初始状态按照label排序，qid=1830得到的序列是1,1,1,1,0,0,0,0,0,0，计算dcg:</p>
<span>$$\begin{gather*}
ideal_dcg(qid =1830) =\frac{2^{1}-1}{\log _{2}(1+1)}+\frac{2^{1}-1}{\log _{2}(2+1)}+\ldots
\begin{aligned}+\frac{2^{0}-1}{\log _{2}(10+1)} &amp; \\ &amp;=1+0.631+0.5+0.431+0+0+0+0+0+0 \\ &amp;=2.562 \end{aligned}
\end{gather*}$$</span><!-- Has MathJax -->
<p>两者相除得到初始状态下qid=1830的ndcg:</p>
<span>$$\begin{gather*}

ndcg(qid=1830)=\frac{dcg(qid=1830)}{ideal_{-} ndcg(qid=1830)}=\frac{1.466}{2.562}=0.572

\end{gather*}$$</span><!-- Has MathJax -->
<p>下面要计算每一个doc的deltaNDCG，公式如下：</p>
<span>$$\begin{gather*}
\begin{array}{c}
\operatorname{deltaNDCG}(i, j) \\
=| \text {ndcg(original sequence) }-ndcg(\operatorname{swap}(i, j) \text { sequence }) |
\end{array}
\end{gather*}$$</span><!-- Has MathJax -->
<p>deltaNDCG(i,j)是将位置i和位置j的位置互换后产生的ndcg变化（其他位置均不变），显然有相同label的deltaNDCG(i,j)=0。在qid=1830的初始序列0, 0, 0, 1, 1, 0, 1, 1, 0, 0，由于前3的label都一样，所以deltaNDCG(1,2)=deltaNDCG(1,3)=0，不为0的是deltaNDCG(1,4), deltaNDCG(1,5), deltaNDCG(1,7), deltaNDCG(1,8)。将1，4位置互换，序列变为1, 0, 0, 0, 1, 0, 1, 1, 0, 0，计算得到dcg=2.036，整个deltaNDCG(1,4)的计算过程如下：</p>
<span>$$\begin{gather*}
\begin{array}{l}
\qquad \begin{array}{l}
dcg(q i d=1830, \operatorname{swap}(1,4))=\frac{2^{1}-1}{\log _{2}(1+1)}+\frac{2^{0}-1}{\log _{2}(2+1)}+\ldots \\
+\frac{2^{0}-1}{\log _{2}(10+1)}
\end{array} \\
=1+0+0+0+0.387+0+0.333+0.315+0+0 \\
=2.036
\end{array}
\end{gather*}$$</span><!-- Has MathJax -->
<span>$$\begin{gather*}
\begin{array}{l}
n d c g(swap(1,4))=\frac{d c g(swap(1,4))}{ideal_{-} dcg}=\frac{2.036}{2.562}=0.795 \\
\text {deltaNDCG}(1,4)=\operatorname{detal} N D C G(4,1) \\
=| \text {ndcg}(\text {original sequence})-\text {ndcg}(\operatorname{swap}(1,4)) | \\
=|0.572-0.795|=0.222
\end{array}
\end{gather*}$$</span><!-- Has MathJax -->
<p>同样过程可以计算出deltaNDCG(1,5)=0.239, deltaNDCG(1,7)=0.260, deltaNDCG(1,8)=0.267等。</p>
<p>进一步，要计算lambda(i)，根据paper，还需要ρ值，ρ可以理解为$doc_i$比$doc_j$差的概率，其计算公式为：</p>
<span>$\rho_{i j}=\frac{1}{1+e^{\sigma\left(s_{i}-s_{j}\right)}}$</span><!-- Has MathJax -->
<p>参考<a href="[http://octopuscoder.github.io/2020/01/19/%E6%90%9C%E7%B4%A2%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/](http://octopuscoder.github.io/2020/01/19/搜索排序算法/">搜索排序算法</a>)中关于LambdaRank的介绍：</p>
<span>$$\begin{gather*}

\lambda_{i j}=\frac{\partial C\left(s_{i}-s_{j}\right)}{\partial s_{i}}=\frac{-\sigma}{1+e^{\sigma\left(s_{i}-s_{j}\right)}}\left|\Delta_{N D C G}\right|

\end{gather*}$$</span><!-- Has MathJax -->
<p>Ranklib中直接取σ=1，如下图，蓝，红，绿三种颜色分别对应σ=1，2，4时ρ函数的曲线情形（横坐标是<span>$s_i-s_j$</span><!-- Has MathJax -->）:</p>
<p>初始时，模型为空，所有模型预测得分都是0，所以<span>$s_i=s_j=0，&rho;_{ij}=1/2$</span><!-- Has MathJax -->，lambda(i,j)的计算公式为：</p>
<span>$$\begin{gather*}

\lambda_{i j}=\rho_{i j} *|\operatorname{deltaNDCG}(i, j)|

\end{gather*}$$</span><!-- Has MathJax -->
<p>上式为Ranklib中实际使用的公式，而在paper中，还需要再乘以-σ，在σ=1时，就是符号正好相反，这两种方式是等价的，符号并不影响模型训练结果（其实大可以把代码中lambda的值前面加一个负号，只是注意在每轮计算train, valid和最后计算test的ndcg的时候，模型预测的得分modelScores要按升序排列——越负的doc越好，而不是源代码中按降序。最后训练出的模型是一样的，这说明这两种方式完全对称，所以符号的问题可以省略。甚至不乘以-σ，更符合人的习惯——分数越大越好，降序排列结果。）：</p>
<span>$$\begin{gather*}

\lambda_{i}=\sum_{j(l a b e l(i)&gt;l a b e l(j))} \lambda_{i j}-\sum_{j(label(i)&lt;label(j))} \lambda_{i j}

\end{gather*}$$</span><!-- Has MathJax -->
<p>计算<span>$\lambda_{1}$</span><!-- Has MathJax -->，由于label(1)=0，qid=1830中的其他doc的label都大于或者等于0，所以<span>$\lambda_{1}$</span><!-- Has MathJax -->的计算中所有的<span>$\lambda_{1,j}$</span><!-- Has MathJax -->都为负项。将之前计算的各<span>$deltaNDCG(1,j)$</span><!-- Has MathJax -->代入，且初始状态下<span>$&rho;_{ij}=1/2$</span><!-- Has MathJax -->，所以:</p>
<span>$$\begin{gather*}*

\begin{aligned}
\lambda_{1} &amp;=-0.5 *(\text {deltaNDCG}(1,3)+\text {deltaNDCG}(1,4)+\text {deltaNDCG}(1,6)+\text {deltaNDCG}(1,7)) \\
&amp;=-0.5 *(0.222+0.239+0.260+0.267)=-0.495
\end{aligned}

\end{gather*}$$</span><!-- Has MathJax -->
<p>可以计算出初始状态下qid=1830各个doc的lambda值，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">qId=<span class="number">1830</span>    <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">-0.111</span>  <span class="number">-0.120</span>  <span class="number">0.000</span>   <span class="number">-0.130</span>  <span class="number">-0.134</span>  <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="keyword">lambda</span>(<span class="number">1</span>): <span class="number">-0.495</span></div><div class="line">qId=<span class="number">1830</span>    <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">-0.039</span>  <span class="number">-0.048</span>  <span class="number">0.000</span>   <span class="number">-0.058</span>  <span class="number">-0.062</span>  <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="keyword">lambda</span>(<span class="number">2</span>): <span class="number">-0.206</span></div><div class="line">qId=<span class="number">1830</span>    <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">-0.014</span>  <span class="number">-0.022</span>  <span class="number">0.000</span>   <span class="number">-0.033</span>  <span class="number">-0.036</span>  <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="keyword">lambda</span>(<span class="number">3</span>): <span class="number">-0.104</span></div><div class="line">qId=<span class="number">1830</span>    <span class="number">0.111</span>   <span class="number">0.039</span>   <span class="number">0.014</span>   <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">0.015</span>   <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">0.025</span>   <span class="number">0.028</span>   <span class="keyword">lambda</span>(<span class="number">4</span>): <span class="number">0.231</span> </div><div class="line">qId=<span class="number">1830</span>    <span class="number">0.120</span>   <span class="number">0.048</span>   <span class="number">0.022</span>   <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">0.006</span>   <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">0.017</span>   <span class="number">0.019</span>   <span class="keyword">lambda</span>(<span class="number">5</span>): <span class="number">0.231</span> </div><div class="line">qId=<span class="number">1830</span>    <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">-0.015</span>  <span class="number">-0.006</span>  <span class="number">0.000</span>   <span class="number">-0.004</span>  <span class="number">-0.008</span>  <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="keyword">lambda</span>(<span class="number">6</span>): <span class="number">-0.033</span></div><div class="line">qId=<span class="number">1830</span>    <span class="number">0.130</span>   <span class="number">0.058</span>   <span class="number">0.033</span>   <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">0.004</span>   <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">0.006</span>   <span class="number">0.009</span>   <span class="keyword">lambda</span>(<span class="number">7</span>): <span class="number">0.240</span> </div><div class="line">qId=<span class="number">1830</span>    <span class="number">0.134</span>   <span class="number">0.062</span>   <span class="number">0.036</span>   <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">0.008</span>   <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">0.003</span>   <span class="number">0.005</span>   <span class="keyword">lambda</span>(<span class="number">8</span>): <span class="number">0.247</span> </div><div class="line">qId=<span class="number">1830</span>    <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">-0.025</span>  <span class="number">-0.017</span>  <span class="number">0.000</span>   <span class="number">-0.006</span>  <span class="number">-0.003</span>  <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="keyword">lambda</span>(<span class="number">9</span>): <span class="number">-0.051</span></div><div class="line">qId=<span class="number">1830</span>    <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="number">-0.028</span>  <span class="number">-0.019</span>  <span class="number">0.000</span>   <span class="number">-0.009</span>  <span class="number">-0.005</span>  <span class="number">0.000</span>   <span class="number">0.000</span>   <span class="keyword">lambda</span>(<span class="number">10</span>): <span class="number">-0.061</span></div></pre></td></tr></table></figure>
<p>上表中每一列都是考虑了符号的<span>$\lambda_{i,j}$</span><!-- Has MathJax -->，即如果label(i)<label(j)，则为负值，反之为正值，每行结尾的<span>$\lambda_i$<!-- Has MathJax -->是前面的加和，即为最终的<span>$\lambda_i$</span><!-- Has MathJax -->。可以看到，<span>$\lambda_i$</span><!-- Has MathJax -->在系统中表达了<span>$doc_i$</span><!-- Has MathJax -->上升或者下降的强度，label越高，位置越后，<span>$\lambda_i$</span><!-- Has MathJax -->为正值，越大，表示趋向上升的方向，力度也越大；label越小，位置越靠前，<span>$\lambda_i$</span><!-- Has MathJax -->为负值，越小，表示趋向下降的方向，力度也大（<span>$\lambda_i$</span><!-- Has MathJax -->的绝对值表达了上升、下降的强度）。</label(j)，则为负值，反之为正值，每行结尾的<span></p>
<p>完成各doc的<span>$\lambda$</span><!-- Has MathJax -->值计算后，Regression Tree便开始以每个doc的<span>$\lambda$</span><!-- Has MathJax -->值为目标，训练模型。并在最后对叶子节点上的样本 <span>$\lambda$</span><!-- Has MathJax -->均值还原成 𝛾 ，乘以learningRate加到此前的Regression Trees上，更新score，重新对query下的doc按score排序，再次计算deltaNDCG以及 λ ，如此迭代下去直至树的数目达到参数设定或者在validation集上不再持续变好（一般实践来说不在模型训练时设置validation集合，因为validation集合一般比训练集合小很多，很容易收敛，达不到效果，不如训练时一步到位，然后另起test集合做结果评估）。</p>
<p>Regression Tree的训练最主要的就是决定如何分裂节点。lambdaMART采用最朴素的最小二乘法，也就是最小化平方误差和来分裂节点：即对于某个选定的feature，选定一个值val，所有&lt;=val的样本分到左子节点，&gt;val的分到右子节点。然后分别对左右两个节点计算平方误差和，并加在一起作为这次分裂的代价。遍历所有feature以及所有可能的分裂点val(每个feature按值排序，每个不同的值都是可能的分裂点)，在这些分裂中找到代价最小的。</p>
<p>继续上面的例子，假设样本只有上面计算出 λ 的10个：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">qId=<span class="number">1830</span> features <span class="keyword">and</span> lambdas</div><div class="line">qId=<span class="number">1830</span>    <span class="number">1</span>:<span class="number">0.003</span> <span class="number">2</span>:<span class="number">0.000</span> <span class="number">3</span>:<span class="number">0.000</span> <span class="number">4</span>:<span class="number">0.000</span> <span class="number">5</span>:<span class="number">0.003</span> <span class="number">6</span>:<span class="number">0.000</span> <span class="number">7</span>:<span class="number">0.000</span> <span class="number">8</span>:<span class="number">0.000</span> <span class="number">9</span>:<span class="number">0.000</span> <span class="number">10</span>:<span class="number">0.000</span>    <span class="keyword">lambda</span>(<span class="number">1</span>):<span class="number">-0.495</span></div><div class="line">qId=<span class="number">1830</span>    <span class="number">1</span>:<span class="number">0.026</span> <span class="number">2</span>:<span class="number">0.125</span> <span class="number">3</span>:<span class="number">0.000</span> <span class="number">4</span>:<span class="number">0.000</span> <span class="number">5</span>:<span class="number">0.027</span> <span class="number">6</span>:<span class="number">0.000</span> <span class="number">7</span>:<span class="number">0.000</span> <span class="number">8</span>:<span class="number">0.000</span> <span class="number">9</span>:<span class="number">0.000</span> <span class="number">10</span>:<span class="number">0.000</span>    <span class="keyword">lambda</span>(<span class="number">2</span>):<span class="number">-0.206</span></div><div class="line">qId=<span class="number">1830</span>    <span class="number">1</span>:<span class="number">0.001</span> <span class="number">2</span>:<span class="number">0.000</span> <span class="number">3</span>:<span class="number">0.000</span> <span class="number">4</span>:<span class="number">0.000</span> <span class="number">5</span>:<span class="number">0.001</span> <span class="number">6</span>:<span class="number">0.000</span> <span class="number">7</span>:<span class="number">0.000</span> <span class="number">8</span>:<span class="number">0.000</span> <span class="number">9</span>:<span class="number">0.000</span> <span class="number">10</span>:<span class="number">0.000</span>    <span class="keyword">lambda</span>(<span class="number">3</span>):<span class="number">-0.104</span></div><div class="line">qId=<span class="number">1830</span>    <span class="number">1</span>:<span class="number">0.189</span> <span class="number">2</span>:<span class="number">0.375</span> <span class="number">3</span>:<span class="number">0.333</span> <span class="number">4</span>:<span class="number">1.000</span> <span class="number">5</span>:<span class="number">0.196</span> <span class="number">6</span>:<span class="number">0.000</span> <span class="number">7</span>:<span class="number">0.000</span> <span class="number">8</span>:<span class="number">0.000</span> <span class="number">9</span>:<span class="number">0.000</span> <span class="number">10</span>:<span class="number">0.000</span>    <span class="keyword">lambda</span>(<span class="number">4</span>):<span class="number">0.231</span></div><div class="line">qId=<span class="number">1830</span>    <span class="number">1</span>:<span class="number">0.078</span> <span class="number">2</span>:<span class="number">0.500</span> <span class="number">3</span>:<span class="number">0.667</span> <span class="number">4</span>:<span class="number">0.000</span> <span class="number">5</span>:<span class="number">0.086</span> <span class="number">6</span>:<span class="number">0.000</span> <span class="number">7</span>:<span class="number">0.000</span> <span class="number">8</span>:<span class="number">0.000</span> <span class="number">9</span>:<span class="number">0.000</span> <span class="number">10</span>:<span class="number">0.000</span>    <span class="keyword">lambda</span>(<span class="number">5</span>):<span class="number">0.231</span></div><div class="line">qId=<span class="number">1830</span>    <span class="number">1</span>:<span class="number">0.075</span> <span class="number">2</span>:<span class="number">0.125</span> <span class="number">3</span>:<span class="number">0.333</span> <span class="number">4</span>:<span class="number">0.000</span> <span class="number">5</span>:<span class="number">0.078</span> <span class="number">6</span>:<span class="number">0.000</span> <span class="number">7</span>:<span class="number">0.000</span> <span class="number">8</span>:<span class="number">0.000</span> <span class="number">9</span>:<span class="number">0.000</span> <span class="number">10</span>:<span class="number">0.000</span>    <span class="keyword">lambda</span>(<span class="number">6</span>):<span class="number">-0.033</span></div><div class="line">qId=<span class="number">1830</span>    <span class="number">1</span>:<span class="number">0.079</span> <span class="number">2</span>:<span class="number">0.250</span> <span class="number">3</span>:<span class="number">0.667</span> <span class="number">4</span>:<span class="number">0.000</span> <span class="number">5</span>:<span class="number">0.085</span> <span class="number">6</span>:<span class="number">0.000</span> <span class="number">7</span>:<span class="number">0.000</span> <span class="number">8</span>:<span class="number">0.000</span> <span class="number">9</span>:<span class="number">0.000</span> <span class="number">10</span>:<span class="number">0.000</span>    <span class="keyword">lambda</span>(<span class="number">7</span>):<span class="number">0.240</span></div><div class="line">qId=<span class="number">1830</span>    <span class="number">1</span>:<span class="number">0.148</span> <span class="number">2</span>:<span class="number">0.000</span> <span class="number">3</span>:<span class="number">0.000</span> <span class="number">4</span>:<span class="number">0.000</span> <span class="number">5</span>:<span class="number">0.148</span> <span class="number">6</span>:<span class="number">0.000</span> <span class="number">7</span>:<span class="number">0.000</span> <span class="number">8</span>:<span class="number">0.000</span> <span class="number">9</span>:<span class="number">0.000</span> <span class="number">10</span>:<span class="number">0.000</span>    <span class="keyword">lambda</span>(<span class="number">8</span>):<span class="number">0.247</span></div><div class="line">qId=<span class="number">1830</span>    <span class="number">1</span>:<span class="number">0.059</span> <span class="number">2</span>:<span class="number">0.000</span> <span class="number">3</span>:<span class="number">0.000</span> <span class="number">4</span>:<span class="number">0.000</span> <span class="number">5</span>:<span class="number">0.059</span> <span class="number">6</span>:<span class="number">0.000</span> <span class="number">7</span>:<span class="number">0.000</span> <span class="number">8</span>:<span class="number">0.000</span> <span class="number">9</span>:<span class="number">0.000</span> <span class="number">10</span>:<span class="number">0.000</span>    <span class="keyword">lambda</span>(<span class="number">9</span>):<span class="number">-0.051</span></div><div class="line">qId=<span class="number">1830</span>    <span class="number">1</span>:<span class="number">0.071</span> <span class="number">2</span>:<span class="number">0.125</span> <span class="number">3</span>:<span class="number">0.333</span> <span class="number">4</span>:<span class="number">0.000</span> <span class="number">5</span>:<span class="number">0.074</span> <span class="number">6</span>:<span class="number">0.000</span> <span class="number">7</span>:<span class="number">0.000</span> <span class="number">8</span>:<span class="number">0.000</span> <span class="number">9</span>:<span class="number">0.000</span> <span class="number">10</span>:<span class="number">0.000</span>    <span class="keyword">lambda</span>(<span class="number">10</span>):<span class="number">-0.061</span></div></pre></td></tr></table></figure>
<p>上表中除了第一列是qid，最后一列是lambda外，其余都是feature，比如我们选择feature(1)的0.059做分裂点，则左子节点&lt;=0.059的doc有: 1, 2, 3, 9；而&gt;0.059的被安排到右子节点，doc有4, 5, 6, 7, 8, 10。由此左右两个子节点的lambda均值分别为：</p>
<span>$$\begin{gather*}

\bar{\lambda}_{L}=\frac{\lambda_{1}+\lambda_{2}+\lambda_{3}+\lambda 9}{4}=\frac{-0.495-0.206-0.104-0.051}{4}=-0.214

\end{gather*}$$</span><!-- Has MathJax -->
<span>$$\begin{gather*}
\begin{array}{l}
\lambda_{R}^{-}=\frac{\lambda_{4}+\lambda_{5}+\lambda_{6}+\lambda 7+\lambda_{8}+\lambda_{10}}{6} \\
=\frac{0.231+0.231-0.033+0.240+0.247-0.061}{6}=0.143
\end{array}
\end{gather*}$$</span><!-- Has MathJax -->
<p>继续计算左右子节点的平方误差和：</p>
<span>$$\begin{gather*}
\begin{aligned}
&amp;s_{L}=\sum_{i \in L}\left(\lambda_{i}-\bar{\lambda}_{L}\right)^{2}=(-0.495+0.214)^{2}\\
&amp;+(-0.206+0.214)^{2}+(-0.104+0.214)^{2}\\
&amp;+(-0.051+0.214)^{2}=0.118\\
&amp;s_{R}=\sum_{i \in R}\left(\lambda_{i}-\bar{\lambda}_{R}\right)^{2}=(0.231-0.143)^{2}\\
&amp;+(0.231-0.143)^{2}+(-0.033-0.143)^{2}\\
&amp;+(0.240-0.143)^{2}+(0.247-0.143)^{2}\\
&amp;+(0.016-0.143)^{2}=0.083
\end{aligned}
\end{gather*}$$</span><!-- Has MathJax -->
<p>因此将feature(1)的0.059作为分裂点时的均方差（分裂代价）是：</p>
<span>$$\begin{gather*}
\cos t_{0.059 @ \text { feature}(1)}=s_{L}+s_{R}=0.118+0.083=0.201
\end{gather*}$$</span><!-- Has MathJax -->
<p>我们可以像上面那样遍历所有feature的不同值，尝试分裂，计算Cost，最终选择所有可能分裂中最小Cost的那一个作为分裂点。然后将𝑠𝐿和𝑠𝑅 分别作为左右子节点的属性存储起来，并把分裂的样本也分别存储到左右子节点中，然后维护一个队列，始终按平方误差和s降序插入新分裂出的节点，每次从该队列头部拿出一个节点（并基于这个节点上的样本）进行分裂（即最大均方差优先分裂），直到树的分裂次数达到参数设定（训练时传入的leaf值，叶子节点的个数与分裂次数等价）。这样就完成了一棵Regression Tree的训练。</p>
<p>上面讲述了一棵树的标准分裂过程，此外，树的分裂还包含了其他参数设定，例如叶子节点上的最少样本数，比如我们设定为3，则在feature(1)处，0.001和0.003两个值都不能作为分裂点，因为用它们做分裂点，左子树的样本数分别是1和2，均&lt;3。叶子节点的最少样本数越小，模型则拟合得越好，当然也容易过拟合（over-fitting）；反之如果设置得越大，模型则可能欠拟合（under-fitting），实践中可以使用cross validation的办法来寻找最佳的参数设定。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://zhuanlan.zhihu.com/p/57814935" target="_blank" rel="external">GBT、GBDT、GBRT与Xgboost</a></p>
<p><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf" target="_blank" rel="external">From RankNet to LambdaRank to LambdaMART: An Overview</a></p>
<p><a href="https://www.cnblogs.com/wowarsenal/p/3900359.html" target="_blank" rel="external">LambdaMART简介——基于Ranklib源码</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/19/搜索排序算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jeb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小菜鸡">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/19/搜索排序算法/" itemprop="url">搜索排序算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-19T15:56:07+08:00">
                2020-01-19
              </time>
            

            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<p><strong><em>[待进一步整理]</em></strong></p>
<h1 id="算法框架"><a href="#算法框架" class="headerlink" title="算法框架"></a>算法框架</h1><p>典型的搜索排序算法框架如下图所示，分为线下训练和线上排序两个部分。模型包括相关性模型、时效性模型、个性化模型和点击模型等。特征包括Query特征、Doc特征、User特征和Query-Doc匹配特征等。日志包括展现日志、点击日志和Query日志。<br><img width="700" src="/images/search_structure.png"></p>
<h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><h2 id="泛特征"><a href="#泛特征" class="headerlink" title="泛特征"></a>泛特征</h2><p>Query特征：意图分类、关键词、词权重等。<br>Doc特征：文章分类、长度、点赞数等。<br>User特征：年龄、性别等。<br>Query-Doc匹配特征：类别匹配、BM25。<br>点击特征：CTR、首次点击等。</p>
<h1 id="日志设计"><a href="#日志设计" class="headerlink" title="日志设计"></a>日志设计</h1><p>展现日志：理论上可根据经验进行人工标注打分，并且作为模型的启动训练数据。<br>点击日志：用户的点击行为日志，可以用于Query日志挖掘，进行查询扩展等，例如多个query搜索结果用户都点击了同一篇文档，则可认为这些query相似。<br>Query日志：用于和点击／转化数据做联合分析。</p>
<h1 id="模型介绍"><a href="#模型介绍" class="headerlink" title="模型介绍"></a>模型介绍</h1><p>相关性模型：Learning to Rank模型</p>
<ol>
<li>按照样本生成方法和Loss Function不同分为point wise、pair wise和list wise三种，参考<a href="https://wesure.lexiangla.com/teams/dm/docs/1665fb8a09d111ea81c20a58ac131706?company_from=wesure" target="_blank" rel="external">L2R算法介绍</a>。2019年Google提出的group wise模型 TF Ranking。</li>
<li>按照模型结构划分，可分为线性排序模型、树模型、深度学习模型，以及组合模型（GBDT+LR，Deep&amp;Wide）。</li>
</ol>
<p>时效性模型：[待补充]。<br>个性化模型：逻辑回归(Logistic Regression）。<br>点击模型：深度置信网络(DeepBeliefNetworks)。</p>
<h2 id="相关性模型"><a href="#相关性模型" class="headerlink" title="相关性模型"></a>相关性模型</h2><h3 id="模型分类"><a href="#模型分类" class="headerlink" title="模型分类"></a>模型分类</h3><p><img width="700" src="/images/search_kinds.png"></p>
<h3 id="迭代过程"><a href="#迭代过程" class="headerlink" title="迭代过程"></a>迭代过程</h3><p><img width="700" src="/images/search_process.png"></p>
<h3 id="主流模型及评测指标"><a href="#主流模型及评测指标" class="headerlink" title="主流模型及评测指标"></a>主流模型及评测指标</h3><p><img width="700" src="/images/search_evalute.png"></p>
<h3 id="主流模型对比"><a href="#主流模型对比" class="headerlink" title="主流模型对比"></a>主流模型对比</h3><p><img height="500" src="/images/serach_model_compare.png"></p>
<p>图中Rank Creation指给定查询Query和文档Docs，得到Docs排序结果；Rank Aggregation指综合多个不同的Ranking System的排序结果，得出最终排序结果。</p>
<h3 id="模型详情"><a href="#模型详情" class="headerlink" title="模型详情"></a>模型详情</h3><h4 id="RankSVM"><a href="#RankSVM" class="headerlink" title="RankSVM"></a>RankSVM</h4><p>RankSVM(2003)，将排序问题转化为pairwise的分类问题，然后使用SVM分类模型进行学习并求解，举例说明，两组query及其召回的documents，其中query-doc的相关程度等级分为三档，如下图所示：<br><img width="700" src="/images/search_ranksvm1.png"><br>同一个query下的不同相关度的doc的feature vector可以进行组合，形成新的feature vector：x1-x2，x1-x3，x2-x3。同时label也会被重新赋值，例如L1-L2，L1-L3，L2-L3。这几个feature vector的label被赋值成分类问题中的positive label。进一步，为了形成一个标准的分类问题，我们还需要有negative samples，这里我们就使用前述的几个新的positive feature vector的反方向向量作为相应的negative samples：x2-x1，x3-x1，x3-x2。另外，需要注意的是，我们在组合形成新的feature vector的时候，不能使用在原始排序问题中处于相同相似度等级的两个feature vector，也不能使用处于不同query下的两个feature vector。<br><img width="700" src="/images/search_ranksvm2.png"></p>
<h4 id="RankNet"><a href="#RankNet" class="headerlink" title="RankNet"></a>RankNet</h4><p>微软(2005)提出，属于pairwise算法，从概率的角度来解决排序问题。RankNet的核心是提出了一种概率损失函数来学习Ranking Function，并应用Ranking Function对文档进行排序。这里的Ranking Function可以是任意对参数可微的模型，也就是说，该概率损失函数并不依赖于特定的机器学习模型，在论文中，RankNet是基于神经网络实现的。除此之外，GBDT等模型也可以应用于该框架。<br>对于任意一个doc对(Ui,Uj)，模型输出的score分别为si和sj，那么根据模型的预测，Ui比Uj与Query更相关的概率为Pij。由于RankNet使用的模型一般为神经网络，根据经验sigmoid函数能提供一个比较好的概率评估。<br>那么根据模型的预测，Ui比Uj与Query更相关的概率为：<br><span>$$\begin{gather*}
P_{i j}=P\left(U_{i}&gt;U_{j}\right)=\frac{1}{1+e^{-\sigma\left(s_{i}-s_{j}\right)}}
\end{gather*}$$</span><!-- Has MathJax --><br><strong><em>RankNet证明了如果知道一个待排序文档的排列中相邻两个文档之间的排序概率，则通过推导可以算出每两个文档之间的排序概率。因此对于一个待排序文档序列，只需计算相邻文档之间的排序概率，不需要计算所有pair，减少计算量。</em></strong><br>对于训练数据中的Ui和Uj，它们都包含有一个与Query相关性的真实label，比如Ui与Query的相关性label为good，Uj与Query的相关性label为bad，那么显然Ui比Uj更相关。我们定义Ui比Uj更相关的真实概率为Sij：<br><span>$$\begin{gather*}
\bar{P}_{i j}=\frac{1}{2}\left(1+S_{i j}\right)
\end{gather*}$$</span><!-- Has MathJax --><br>如果$U_i$比$U_j$更相关，那么Sij=1；如果Ui不如Uj相关，那么Sij=−1；如果$U_i$、$U_j$与Query的相关程度相同，那么Sij=0。通常，两个doc的相关度可由人工标注或者从搜索日志中得到。<br>对于一个排序，RankNet从各个doc的相对关系来评价排序结果的好坏，排序的效果越好，那么有错误相对关系的doc pair就越少。所谓错误的相对关系即如果根据模型输出Ui排在Uj前面，但真实label为Ui的相关性小于Uj，那么就记一个错误pair，RankNet本质上就是以错误的pair最少为优化目标。而在抽象成cost function时，RankNet实际上是引入了概率的思想：不是直接判断Ui排在Uj前面，而是说Ui以一定的概率P排在Uj前面，即是以预测概率与真实概率的差距最小作为优化目标。最后，RankNet使用Cross Entropy作为cost function，来衡量预测相关性概率对真实相关性概率的拟合程度：<br><span>$$\begin{gather*}
C=-\bar{P}_{i j} \log P_{i j}-\left(1-\bar{P}_{i j}\right) \log \left(1-P_{i j}\right)
\end{gather*}$$</span><!-- Has MathJax --><br>该损失函数有以下两个特点：<br>进一步化简后有：<br><span>$$\begin{gather*}
\begin{aligned}
C_{i j} &amp;=-\frac{1}{2}\left(1+S_{i j}\right) \log \frac{1}{1+e^{-\sigma\left(s_{i}-s_{j}\right)}}-\frac{1}{2}\left(1-S_{i j}\right) \log \frac{e^{-\sigma\left(s_{i}-s_{j}\right)}}{1+e^{-\sigma\left(s_{i}-s_{j}\right)}} \\
&amp;=-\frac{1}{2}\left(1+S_{i j}\right) \log \frac{1}{1+e^{-\sigma\left(s_{i}-s_{j}\right)}}-\frac{1}{2}\left(1-S_{i j}\right)\left[-\sigma\left(s_{i}-s_{j}\right)+\log \frac{1}{1+e^{-\sigma\left(s_{i}-s_{j}\right)}}\right] \\
&amp;=\frac{1}{2}\left(1-S_{i j}\right) \sigma\left(s_{i}-s_{j}\right)+\log \left(1+e^{-\sigma\left(s_{i}-s_{j}\right)}\right)
\end{aligned}
\end{gather*}$$</span><!-- Has MathJax --><br>当Sij=1，有：<br><span>$$\begin{gather*}
C=\log \left(1+e^{-\sigma\left(s_{i}-s_{j}\right)}\right)
\end{gather*}$$</span><!-- Has MathJax --><br>当Sij=-1，有：<br><span>$$\begin{gather*}
C=\log \left(1+e^{-\sigma\left(s_{j}-s_{i}\right)}\right)
\end{gather*}$$</span><!-- Has MathJax --><br>下图展示了当Sij分别取1，0，-1的时候cost function以si-sj为变量的函数图像：<br><img width="700" src="/images/search_fun_pic.png"><br>可以看到当Sij=1时，模型预测的si比sj越大，其代价越小；Sij=−1时，si比sj越小，代价越小；Sij=0时，代价的最小值在si与sj相等处取得。<br>该损失函数有下面两个特点：</p>
<ol>
<li>当两个相关性不同的文档算出来的模型分数相同时，损失函数的值大于0，仍会对这对pair做惩罚，使他们的排序位置区分开。</li>
<li>损失函数是一个类线性函数，可以有效减少异常样本数据对模型的影响，因此具有鲁棒性。</li>
</ol>
<p>代价函数C可微，下面就可以用随机梯度下降法来迭代更新模型参数wk了，即：<br><span>$$\begin{gather*}
w_{k} \rightarrow w_{k}-\eta \frac{\partial C}{\partial w_{k}}
\end{gather*}$$</span><!-- Has MathJax --><br>η为步长，代价C沿负梯度方向变化：<br><span>$$\begin{gather*}
\Delta C=\sum_{k} \frac{\partial C}{\partial w_{k}} \Delta w_{k}=\sum_{k} \frac{\partial C}{\partial w_{k}}\left(\eta \frac{\partial C}{\partial w_{k}}\right)=-\eta \sum_{k}\left(\frac{\partial C}{\partial w_{k}}\right)^{2}&lt;0
\end{gather*}$$</span><!-- Has MathJax --><br>这表明沿负梯度方向更新参数确实可以降低总代价。<br>随机梯度下降法时，有：<br><span>$$\begin{gather*}
\begin{aligned}
\frac{\partial C}{\partial w_{k}} &amp;=\frac{\partial C}{\partial s_{i}} \frac{\partial s_{i}}{\partial w_{k}}+\frac{\partial C}{\partial s_{j}} \frac{\partial s_{j}}{\partial w_{k}}=\sigma\left(\frac{1}{2}\left(1-S_{i j}\right)-\frac{1}{1+e^{\sigma\left(s_{i}-s_{j}\right)}}\right)\left(\frac{\partial s_{i}}{\partial w_{k}}-\frac{\partial s_{j}}{\partial w_{k}}\right) \\
&amp;=\lambda_{i j}\left(\frac{\partial s_{i}}{\partial w_{k}}-\frac{\partial s_{j}}{\partial w_{k}}\right)
\end{aligned}
\end{gather*}$$</span><!-- Has MathJax --><br>其中：<br><span>$$\begin{gather*}
\lambda_{i j} \equiv \frac{\partial C\left(s_{i}-s_{j}\right)}{\partial s_{i}}=\sigma\left(\frac{1}{2}\left(1-S_{i j}\right)-\frac{1}{1+e^{\sigma\left(s_{i}-s_{j}\right)}}\right)
\end{gather*}$$</span><!-- Has MathJax --><br>上面的是对于每一对pair都会进行一次权重的更新，其实是可以对同一个query下的所有文档pair全部带入神经网络进行前向预测，然后计算总差分并进行误差后向反馈，这样将大大减少误差反向传播的次数，加速RankNet训练过程，即利用批处理的梯度下降法：<br><span>$$\begin{gather*}
\frac{\partial C}{\partial w_{k}}=\sum_{(i, j) \in I}\left(\frac{\partial C_{i j}}{\partial s_{i}} \frac{\partial s_{i}}{\partial w_{k}}+\frac{\partial C_{i j}}{\partial s_{j}} \frac{\partial s_{j}}{\partial w_{k}}\right)
\end{gather*}$$</span><!-- Has MathJax --><br>其中：<br><span>$$\begin{gather*}
\frac{\partial C_{i j}}{\partial s_{i}}=\sigma\left(\frac{1}{2}\left(1-S_{i j}\right)-\frac{1}{1+e^{\sigma\left(s_{i}-s_{j}\right)}}\right)=-\frac{\partial C_{i j}}{\partial s_{j}}
\end{gather*}$$</span><!-- Has MathJax --><br>令：<br><span>$$\begin{gather*}
\lambda_{i j}=\frac{\partial C_{i j}}{\partial s_{i}}=\sigma\left(\frac{1}{2}\left(1-S_{i j}\right)-\frac{1}{1+e^{o\left(s_{i}-s_{j}\right)}}\right)
\end{gather*}$$</span><!-- Has MathJax --><br>有：<br><span>$$\begin{gather*}
\begin{aligned}
\frac{\partial C}{\partial w_{k}} &amp;=\sum_{(i, j) \in I} \sigma\left(\frac{1}{2}\left(1-S_{i j}\right)-\frac{1}{1+e^{\sigma\left(s_{i}-s_{j}\right)}}\right)\left(\frac{\partial s_{i}}{\partial w_{k}}-\frac{\partial s_{j}}{\partial w_{k}}\right) \\
&amp;=\sum_{(i, j) \in I} \lambda_{i j}\left(\frac{\partial s_{i}}{\partial w_{k}}-\frac{\partial s_{j}}{\partial w_{k}}\right) \\
&amp;=\sum_{i} \lambda_{i} \frac{\partial s_{i}}{\partial w_{k}}
\end{aligned}
\end{gather*}$$</span><!-- Has MathJax --></p>
<p>如何理解上式最后一步的化简及λi的意义呢？前面讲过集合I中只包含label不同的doc的集合，且每个pair仅包含一次，即(Ui,Uj)与(Uj,Ui)等价。为方便起见，我们假设I中只包含Ui相关性大于Uj的pair(Ui,Uj)，即I中的pair均满足Sij=1，那么：<br><span>$$\begin{gather*}
\lambda_{i}=\sum_{j:(i, j) \in I} \lambda_{i j}-\sum_{k:(k, i) \in I} \lambda_{k i}
\end{gather*}$$</span><!-- Has MathJax --><br>举例说明，假设有三个doc，其真实相关性满足U1&gt;U2&gt;U3，那么集合I中就包含{(1,2), (1,3), (2,3)}共三个pair，则：<br><span>$$\begin{gather*}
\frac{\partial C}{\partial w_{k}}=\left(\lambda_{12} \frac{\partial s_{1}}{\partial w_{k}}-\lambda_{12} \frac{\partial s_{2}}{\partial w_{k}}\right)+\left(\lambda_{13} \frac{\partial s_{1}}{\partial w_{k}}-\lambda_{13} \frac{\partial s_{3}}{\partial w_{k}}\right)+\left(\lambda_{23} \frac{\partial s_{2}}{\partial w_{k}}-\lambda_{23} \frac{\partial s_{3}}{\partial w_{k}}\right)
\end{gather*}$$</span><!-- Has MathJax --><br>显然λ1=λ12+λ13，λ2=λ23−λ12，λ3=−λ13−λ23。<br><strong><em>λi决定着第i个doc在迭代中的移动方向和幅度，真实的排在Ui前面的doc越少，排在Ui后面的doc越多，那么文档Ui向前移动的幅度就越大。</em></strong><br>如何理解呢？我们可以结合损失函数C的图像来看，第i个doc与query越相关，λi越大，则wk变化越大，损失函数C减少越多，而损失函数C的图像在Sij=1时越小，si-sj越大，表明模型输出的文档i的分数与文档j分数相差越大，即文档Ui向前移动的幅度就越大。</p>
<h4 id="GBrank"><a href="#GBrank" class="headerlink" title="GBrank"></a>GBrank</h4><p><strong><em>基本思想：对两个具有relative relevance judgment的Documents，利用pairwise的方式构造一个特殊的 loss function，再使用GBDT的方法来对此loss function进行优化，求解其极小值。</em></strong><br>GBRank的创新点之一就在于构造一个特殊的loss function。首先，我们需要构造pair，即在同一个query下有两个doc，可以通过人工标注或者搜索日志来对这两个doc与该query的相关程度进行判断，得到一个pair关系，即其中一个doc的相关程度要比另一个doc的相关程度更高，这就是relative relevance judgment。一旦我们有了这个pairwise的相对关系，问题就成了如何利用这些doc pair学习出一个排序模型。<br>假设我们有以下的preference pairs 作为training data：<br><span>$$\begin{gather*}
\left\{\left(x_{i}^{(1)}, x_{i}^{(2)}\right), x_{i}^{(1)}&gt;x_{i}^{(2)}\right\}_{i=1}^{N}
\end{gather*}$$</span><!-- Has MathJax --><br>则可构造损失函数L(f)，与SVM中hinge loss类似:<br><span>$$\begin{gather*}
L(f)=\frac{1}{2} \sum_{i=1}^{N}\left(\max \left\{0, \tau-\left(f\left(x_{i}^{(1)}\right)-f\left(x_{i}^{(2)}\right)\right\}\right)^{2}\right.
\end{gather*}$$</span><!-- Has MathJax --><br>在hinge loss的基础上，将原来为1的参数改成了τ。即当两个doc相关度差距达到τ以上的时候，loss才为0。若f(x)输出固定，那么损失函数最少，但不是训练目标。<br>然后问题就变成了怎样对这个loss function进行优化求解极小值。这里使用了GBDT的思想，即Functional Gradient Descent的方法。</p>
<blockquote>
<p>在GBDT中，Functional Gradient Descent的使用为：将需要求解的f(x)表示成一个additive model，即将一个函数分解为若干个小函数的加和形式，而这每个小函数的产生过程是串行生成的，即每个小函数都是在拟合loss function在已有的f(x)上的梯度方向（由于训练数据是有限个数的，所以f(x)是离散值的向量，而此梯度方向也表示成一个离散值的向量），然后将拟合的结果函数进一步更新到f(x)中，形成一个新的f(x)。</p>
</blockquote>
<p>对于loss function，利用Functional Gradient Descent的方法优化为极小值的过程为：将f(x)表示成additive model，每次迭代的时候，用一个regression tree来拟合loss function在当前f(x)上的梯度方向。此时由于训练数据是有限个数的，f(x)同样只是一系列离散值，梯度向量也是一系列离散值，则可使用regression tree来拟合这一系列离散值。<br>但不同之处在于，由于使用pairwise方法，这里的loss function中，有两个不一样的f(x)的离散值，所以每次我们需要对f(x)在这两个点上的值都进行更新，即需要对一个training instance计算两个梯度方向。首先将以下两个变量看作未知变量：<br><span>$$\begin{gather*}
f\left(x_{i}^{(1)}\right), \quad f\left(x_{i}^{(2)}\right), \quad i=1, \cdots, N
\end{gather*}$$</span><!-- Has MathJax --><br>然后求解loss function对这两个未知变量的梯度（分别对两个未知变量求导），如下：<br><span>$$\begin{gather*}
-\max \left\{0, f\left(x_{i}^{(2)}\right)-f\left(x_{i}^{(1)}\right)+\tau\right\}, \quad \max \left\{0, f\left(x_{i}^{(2)}\right)-f\left(x_{i}^{(1)}\right)+\tau\right\}, \quad i=1, \cdots, N
\end{gather*}$$</span><!-- Has MathJax --><br>如果两个变量之差大于0，则此时对应的loss为0，我们无需对f(x)进行迭代更新；反之loss不为0，我们需要对f(x)进行迭代更新，即使得新的f(x)在这个instance上的两个点的预测值能够更接近真实值。f(x)更新类似于梯度下降方法中参数的更新：<br><span>$$\begin{gather*}
f_{k}(x)=f_{k-1}(x)-\eta \nabla L\left(f_{k}(x)\right)
\end{gather*}$$</span><!-- Has MathJax --><br>pairwise方法中，具体为：<br><span>$$\begin{gather*}
\begin{aligned}
&amp;f_{k}\left(x_{i}^{(1)}\right)=f_{k-1}\left(x_{i}^{(1)}\right)+\eta\left(f_{k-1}\left(x_{i}^{(2)}\right)-f_{k-1}\left(x_{i}^{(1)}\right)+\tau\right)\\
&amp;f_{k}\left(x_{i}^{(2)}\right)=f_{k-1}\left(x_{i}^{(2)}\right)-\eta\left(f_{k-1}\left(x_{i}^{(2)}\right)-f_{k-1}\left(x_{i}^{(1)}\right)+\tau\right)
\end{aligned}
\end{gather*}$$</span><!-- Has MathJax --><br>当学习速率η等于1的时候，更新公式即为：<br><span>$$\begin{gather*}
\begin{aligned}
&amp;f_{k}\left(x_{i}^{(1)}\right)=f_{k-1}\left(x_{i}^{(2)}\right)+\tau\\
&amp;f_{k}\left(x_{i}^{(2)}\right)=f_{k-1}\left(x_{i}^{(1)}\right)-\tau
\end{aligned}
\end{gather*}$$</span><!-- Has MathJax --><br>当我们收集到所有loss值不为0的training instance后，我们便得到了其对应的更新值：<br><span>$$\begin{gather*}
\left\{\left(x_{i}^{(1)}, f_{k-1}\left(x_{i}^{(2)}\right)+\tau\right),\left(x_{i}^{(2)}, f_{k-1}\left(x_{i}^{(1)}\right)-\tau\right)\right\}
\end{gather*}$$</span><!-- Has MathJax --><br>接着，使用一棵regression tree对这些数据进行拟合，生成一个拟合函数$g_{k}(x)$，然后将这次迭代更新的拟合函数更新到f(x)中，此处采用线性叠加的方式：<br><span>$$\begin{gather*}
f_{k}(x)=\frac{k f_{k-1}(x)+\beta g_{k}(x)}{k+1}
\end{gather*}$$</span><!-- Has MathJax --><br>其中，ß为shrinking系数。<br>为什么在每次迭代更新的时候，新的regression tree不像GBDT中那样，纯粹地去拟合梯度方向（一个离散值的向量），而是去拟合：<br><span>$$\begin{gather*}
f_{k}(x)=f_{k-1}(x)-\eta \nabla L\left(f_{k}(x)\right)
\end{gather*}$$</span><!-- Has MathJax --><br>这样一个 原始预测值+梯度更新值 后的新预测值向量呢？<br>因为在每次迭代更新的时候，只是取了部分训练数据（即所有loss值不为0的training instance中的doc pair），所以每次拟合的时候，都只是对这部分数据进行训练，得到一个regression tree，然后把这个新的拟合函数（即regression tree）添加到总的预测函数f(x)中去，即这个regression tree在预测时候是需要对所有训练数据，而不是部分数据，进行预测的。所以如果每次迭代是去拟合梯度的话（梯度方向完全有可能与当前的f(x)向量方向相差很大），在预测的时候，这个regression tree对其余数据（并没有参与这个regression tree训练的数据）的预测值会偏离它们原始值较多，而且这个偏离是不在期望之中的，因为这些数据的当前预测值已经相对靠谱了（不会对loss function有贡献）。所以，当每次拟合的目标是 原始f(x)向量 + 梯度向量 的时候，这个新的向量不会跑的太偏（即跟原始向量相差较小），这时候拟合出来的结果regression tree在对整体数据进行预测的时候，也不会跑的太偏，只是会根据梯度方向稍微有所改变，对其它并不需要更新的数据的影响也相对较小。但同时也在逐渐朝着整体的优化方向上去尝试，所以才会这么去做。（以一个队伍在山峰间移动，分别寻找各自合适位置为例）。</p>
<h4 id="LambdaRank"><a href="#LambdaRank" class="headerlink" title="LambdaRank"></a>LambdaRank</h4><p>RankNet以错误pair最少为优化目标的RankNet算法，然而许多时候仅以错误pair数来评价排序的好坏是不够的，像NDCG或者ERR等评价指标就只关注top k个结果的排序，当我们采用RankNet算法时，往往无法以这些指标为优化目标进行迭代，所以RankNet的优化目标和IR评价指标之间还是存在gap的，如下图所示：<br><img width="500" src="/images/search_lambdaRank.png"><br>如上图所示，每个线条表示文档，蓝色表示相关文档，灰色表示不相关文档，RankNet以pairwise error的方式计算cost，左图的cost为13，右图通过把第一个相关文档下调3个位置，第二个文档上条5个位置，将cost降为11，但是像NDCG或者ERR等评价指标只关注top k个结果的排序，在优化过程中下调前面相关文档的位置不是我们想要得到的结果。图 1右图左边黑色的箭头表示RankNet下一轮的调序方向和强度，但我们真正需要的是右边红色箭头代表的方向和强度，即更关注靠前位置的相关文档的排序位置的提升。LambdaRank正是基于这个思想演化而来，其中Lambda指的就是红色箭头，代表下一次迭代优化的方向和强度，也就是梯度。<br>LambdaRank在RankNet的加速算法形式的基础上引入评价指标Z （如NDCG、ERR等），把交换两个文档的位置引起的评价指标的变化|ΔNDCG|，作为其中一个因子，实验表明对模型效果有显著的提升：<br><span>$$\begin{gather*}
\lambda_{i j}=\frac{\partial C\left(s_{i}-s_{j}\right)}{\partial s_{i}}=\frac{-\sigma}{1+e^{\sigma\left(s_{i}-s_{j}\right)}}\left|\Delta_{N D C G}\right|
\end{gather*}$$</span><!-- Has MathJax --><br>ΔNDCG表示将Ui和Uj进行交换，交换后排序的NDCG与交换前排序的NDCG的差值。<br>损失函数的梯度代表了文档下一次迭代优化的方向和强度，由于引入了IR评价指标，Lambda梯度更关注位置靠前的优质文档的排序位置的提升。有效的避免了下调位置靠前优质文档的位置这种情况的发生。LambdaRank相比RankNet的优势在于分解因式后训练速度变快，同时考虑了评价指标，直接对问题求解，效果更明显。</p>
<h4 id="LambdaMART"><a href="#LambdaMART" class="headerlink" title="LambdaMART"></a>LambdaMART</h4><ol>
<li>Mart（Multiple Additive Regression Tree，Mart就是GBDT），定义了一个框架，缺少一个梯度。</li>
<li>LambdaRank重新定义了梯度，赋予了梯度新的物理意义。</li>
</ol>
<p>因此，所有可以使用梯度下降法求解的模型都可以使用这个梯度，MART就是其中一种，将梯度Lambda和MART结合就是大名鼎鼎的LambdaMART。<br>MART的原理是直接在函数空间对函数进行求解，模型结果由许多棵树组成，每棵树的拟合目标是损失函数的梯度，在LambdaMART中就是Lambda。LambdaMART的具体算法过程如下：<br><img width="700" src="/images/search_lambdaMart.png"><br>可以看出LambdaMART的框架其实就是MART，主要的创新在于中间计算的梯度使用的是Lambda，是pairwise的。MART需要设置的参数包括：树的数量M、叶子节点数L和学习率v，这3个参数可以通过验证集调节获取最优参数。</p>
<p>MART输出值的计算：</p>
<ol>
<li><p>首先设置每棵树的最大叶子数，基分类器通过最小平方损失进行分裂，达到最大叶子数量时停止分裂</p>
</li>
<li><p>使用牛顿法得到叶子的输出，计算效用函数对模型得分的二阶导<span>$\frac{\partial \lambda_{i}}{\partial s_{i}}=\frac{\partial^{2} C}{\partial^{2} s_{i}}$</span><!-- Has MathJax --></p>
<span>$$\begin{gather*}

\frac{\partial^{2} C}{\partial^{2} s_{i}}=\sum_{\{i, j\} \rightleftharpoons I} \sigma^{2}\left|\triangle Z_{i j}\right| \rho_{i j}\left(1-\rho_{i j}\right)&NegativeMediumSpace;

\end{gather*}$$</span><!-- Has MathJax -->
</li>
<li><p>得到第m颗树的第k个叶子的输出值:</p>
<span>$$\begin{gather*}

\gamma_{k m}=\frac{\sum_{x_{i} \in R_{k m}} \frac{\partial C}{\partial s_{i}}}{\sum_{x_{i} \in R_{k m}} \frac{\partial^{2} C}{\partial^{2} s_{i}}}=\frac{-\sum_{x_{i} \in R_{k m}} \sum_{\{i, j\} \rightleftharpoons I}\left|\triangle Z_{i j}\right| \rho_{i j}}{\sum_{x_{i} \in R_{k m}} \sum_{\{i, j\} \rightleftharpoons I}\left|\Delta Z_{i j}\right| \sigma \rho_{i j}\left(1-\rho_{i j}\right)}&NegativeMediumSpace;

\end{gather*}$$</span><!-- Has MathJax -->
</li>
<li><p><span>$x_i$</span><!-- Has MathJax -->为第i个样本，<span>$x_{i} \in R_{k m}$</span><!-- Has MathJax -->意味着落入该叶子的样本，这些样本共同决定了该叶子的输出值。</p>
</li>
</ol>
<p>LambdaMART具有很多优势：</p>
<ol>
<li>适用于排序场景：不是传统的通过分类或者回归的方法求解排序问题，而是直接求解;</li>
<li>损失函数可导：通过损失函数的转换，将类似于NDCG这种无法求导的IR评价指标转换成可以求导的函数，并且赋予了梯度的实际物理意义，数学解释非常漂亮;</li>
<li>增量学习：由于每次训练可以在已有的模型上继续训练，因此适合于增量学习;</li>
<li>组合特征：因为采用树模型，因此可以学到不同特征组合情况;</li>
<li>特征选择：因为是基于MART模型，因此也具有MART的优势，可以学到每个特征的重要性，可以做特征选择;</li>
<li>适用于正负样本比例失衡的数据：因为模型的训练对象具有不同label的文档pair，而不是预测每个文档的label，因此对正负样本比例失衡不敏感。</li>
</ol>
<p><strong>LambdaMART是不是很好懂？</strong></p>
<p><img width="300" src="/images/Emoticon1.png"></p>
<p>有较多博客、资料在此戛然而止，好像上述资料已经足够理解LambdaMART了，这也让我一度怀疑自己的IQ，基础和我一样不太好的兄弟们可以进入另一篇博客，我们从提升树、梯度提升树和梯度提升决策树说起，并结合Ranklib源码和具体的例子，以及微软的相关技术报告一起来看看LambdaMART的<a href="">真相</a>。</p>
<blockquote>
<p>爱奇艺实践：<br>在没有加入稀疏类特征之前，我们的模型是LambdaMART模型，在IR领域是最先进的模型，该模型是一个gbdt模型，基于boosting思想，不断增加决策树，来减小残差。该模型在很多竞赛中表现良好，因为不用过多的特征处理，树模型会考虑特征本身的数据分布，同时有很好的学习泛化能力，树结构很难兼容高维稀疏特征，比方说我们的document是上亿级的特征，很难每个节点走一次树的分割，所以对于加入稀疏特征的时候，树模型会遇到瓶颈。但是在处理高维稀疏特征的时候，像LR、FM、FFM可以认为是线性模型，特征的增加并不会对此类模型造成压力，上亿维也没关系。LR模型弱点在于特征组合能力不足，很多情况下特征组合方式比较重要，树模型从根节点到叶子节点的路径其实是一种组合方式。如下图所示：</p>
</blockquote>
<p><img width="700" src="/images/search_iqiyi_lm.png"></p>
<h4 id="深度模型"><a href="#深度模型" class="headerlink" title="深度模型"></a>深度模型</h4><h5 id="DNN"><a href="#DNN" class="headerlink" title="DNN"></a>DNN</h5><p>爱奇艺实现：<br><img width="700" src="/images/search_iqiyi_dnn.jpg"><br>底层是query和document的描述文本做多粒度切词，之后做embedding后加权平均，得到document和query的向量表达，拼接这两组向量，同时再做点积，（两个向量越来越相近，拼接的时候希望上层网络学到两个向量的相似性，需要有足够的样本和正负样例，所以我们自己做了点积）。除了向量特征，模型也适用了稠密特征，即利用gbdt抽取特征，与embedding特征做拼接，最后经过三个全连接层，接sigmoid函数，就可以得到样本的score，并在此基础上用ndcg的衡量标准去计算损失，从而反向优化网络结构。而在online服务侧，则直接用样本去predict得分。这个模型上线之后，效果非常明显。其中，二次搜索率降低（二次搜索率越低越好，说明用户一次搜中）。</p>
<h5 id="Wide-amp-Deep"><a href="#Wide-amp-Deep" class="headerlink" title="Wide&amp;Deep"></a>Wide&amp;Deep</h5><p>美团点评模型框架：<br><img width="700" src="/images/search_wd_structure.png"><br>美团点评模型具体实现：<br><img width="700" src="/images/search_wd_model.png"><br>在训练时，分别对样本数据进行清洗和提权。在特征方面，对于连续特征，用Min-Max方法做归一化。在交叉特征方面，结合业务需求，提炼出多个在业务场景意义比较重大的交叉特征。用Adam做为优化器，用Cross Entropy做为损失函数。在训练期间，与Wide &amp; Deep Learning论文中不同之处在于，将组合特征作为输入层分别输入到对应的Deep组件和Wide组件中。然后在Deep部分将全部输入数据送到3个ReLU层，在最后通过Sigmoid层进行打分。训练数据7000万+，并用超过3000万的测试数据进行线下模型预估。Batch－Size设为50000，Epoch设为20。<br>线上AB实验结果：<br><img width="700" src="/images/search_wd_abtest.png"></p>
<h5 id="LambdaDNN"><a href="#LambdaDNN" class="headerlink" title="LambdaDNN"></a>LambdaDNN</h5><p>大众点评搜索排序模型，基于TensorFlow分布式框架实现。<br><img width="700" src="/images/search_lambdaDnn.png"><br>NDCG的计算公式中，折损的权重是随着位置呈指数变化的。然而实际曝光点击率随位置变化的曲线与NDCG的理论折损值存在着较大的差异。<br>对于移动端的场景来说，用户在下拉滑动列表进行浏览时，视觉的焦点会随着滑屏、翻页而发生变动。例如用户翻到第二页时，往往会重新聚焦，因此，会发现第二页头部的曝光点击率实际上是高于第一页尾部位置的。我们尝试了两种方案去微调NDCG中的指数位置折损：<br>根据实际曝光点击率拟合折损曲线：根据实际统计到的曝光点击率数据，拟合公式替代NDCG中的指数折损公式，绘制的曲线如图12所示。<br>计算Position Bias作为位置折损：Position Bias在业界有较多的讨论，用户点击商户的过程可以分为观察和点击两个步骤：a.用户需要首先看到该商户，而看到商户的概率取决于所在的位置；b.看到商户后点击商户的概率只与商户的相关性有关。步骤a计算的概率即为Position Bias，这块内容可以讨论的东西很多，这里不再详述。<br><img width="700" src="/images/search_ndcg.png"><br>经过上述对NDCG计算改造训练出的LambdaDNN模型，相较Base树模型和Pointwise DNN模型，在业务指标上有了非常显著的提升。<br><img width="700" src="/images/search_lm_dnn_lmDnn.png"></p>
<h5 id="LambdaDeepFM"><a href="#LambdaDeepFM" class="headerlink" title="LambdaDeepFM"></a>LambdaDeepFM</h5><p>[待补充]</p>
<h5 id="LambdaDCN"><a href="#LambdaDCN" class="headerlink" title="LambdaDCN"></a>LambdaDCN</h5><p>Lambda梯度除了与DNN网络相结合外，也可以与绝大部分常见的网络结构相结合。为了进一步学习到更多交叉特征，美团点评团队在LambdaDNN的基础上分别尝试了LambdaDeepFM和LambdaDCN网络；其中DCN网络是一种加入Cross的并行网络结构，交叉的网络每一层的输出特征与第一层的原始输入特征进行显性的两两交叉，相当于每一层学习特征交叉的映射去拟合层之间的残差。<br><img width="700" src="/images/search_lambdaDcn.png"><br>离线的对比实验表明，Lambda梯度与DCN网络结合之后充分发挥了DCN网络的特点，简洁的多项式交叉设计有效地提升模型的训练效果。NDCG指标对比效果如下图所示：<br><img width="500" src="/images/search_dcn_compare.png"></p>
<h4 id="补充模型"><a href="#补充模型" class="headerlink" title="补充模型"></a>补充模型</h4><h5 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h5><p><img width="700" src="/images/search_fm.png"></p>
<h5 id="DSSM"><a href="#DSSM" class="headerlink" title="DSSM"></a>DSSM</h5><p><img width="700" src="/images/search_dssm.png"></p>
<h5 id="点击模型"><a href="#点击模型" class="headerlink" title="点击模型"></a>点击模型</h5><p><img width="700" src="/images/search_click.png"></p>
<h5 id="DBN模型"><a href="#DBN模型" class="headerlink" title="DBN模型"></a>DBN模型</h5><p><img width="700" src="/images/search_dbn.png"></p>
<h5 id="IRGAN"><a href="#IRGAN" class="headerlink" title="IRGAN"></a>IRGAN</h5><p><img width="700" src="/images/search_irgan.png"></p>
<h1 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h1><ol>
<li>LambdaRank</li>
<li>LambdaMART</li>
<li>Wide&amp;Deep</li>
</ol>
<h1 id="模型组合"><a href="#模型组合" class="headerlink" title="模型组合"></a>模型组合</h1><p>爱奇艺实践：<br><img width="700" src="/images/search_model_compare.png"></p>
<blockquote>
<p>针对GBDT和LR模型的优缺点，做了进一步的模型组合的尝试：<br>第一种方式，用 LR 模型把高维稠密特征进行学习，学习出高维特征，把该特征和原始特征做拼接，学习 gbdt 模型。<br>该办法效果不好，提升很弱。<br><strong> 剖析缘由：</strong> 把高维特征刚在一个特征去表达，丢掉了原始的特征。<br>第二种方式，用 gbdt 去学，学习后把样本落入叶子节点信息来进来与高维稠密特征拼接，在此根底上用 LR 学习。<br>该模型效果变差。<br><strong> 剖析缘由：</strong> 点击类和穿插类特征是对排序影响最大的特征，这类特征和大量的稠密类特征做拼接时，重要性被稀释了，导致模型的学习能力变弱。</p>
</blockquote>
<h1 id="工程实现"><a href="#工程实现" class="headerlink" title="工程实现"></a>工程实现</h1><p><strong>Python训练+Golang部署</strong></p>
<ol>
<li>LambdaRank，基于xgboost实现，参考：<a href="https://github.com/dmlc/xgboost/tree/master/demo/rank" target="_blank" rel="external">https://github.com/dmlc/xgboost/tree/master/demo/rank</a></li>
<li>LambdaMART，基于LightGBM实现，参考：<a href="https://github.com/jiangnanboy/learning_to_rank" target="_blank" rel="external">https://github.com/jiangnanboy/learning_to_rank</a></li>
<li>Wide&amp;Deep基于TensorFlow实现，参考：<a href="https://github.com/tensorflow/ranking" target="_blank" rel="external">https://github.com/tensorflow/ranking</a></li>
</ol>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://mp.weixin.qq.com/s/NqVP0ksfLiRLSGkuWxiz5A" target="_blank" rel="external">浅谈微视推荐系统中的特征工程</a><br><a href="https://cloud.tencent.com/developer/news/184638" target="_blank" rel="external">回顾·搜索引擎算法体系简介——排序和意图篇</a><br><a href="https://tech.meituan.com/2017/07/28/dl.html" target="_blank" rel="external">深度学习在美团推荐平台排序中的运用</a><br><a href="https://www.cnblogs.com/bentuwuying/p/6684585.html" target="_blank" rel="external">Learning to Rank算法介绍：GBRank</a><br><a href="https://www.cnblogs.com/bentuwuying/p/6683832.html" target="_blank" rel="external">Learning to Rank算法介绍：RankSVM 和 IR SVM</a><br><a href="https://tech.meituan.com/2019/01/17/dianping-search-deeplearning.html" target="_blank" rel="external">大众点评搜索基于知识图谱的深度学习排序实践</a><br><a href="https://www.cnblogs.com/bentuwuying/p/6690836.html" target="_blank" rel="external">Learning to Rank算法介绍：RankNet，LambdaRank，LambdaMart</a><br><a href="https://cloud.tencent.com/developer/article/1500313" target="_blank" rel="external">「回顾」爱奇艺搜索排序模型迭代之路</a><br><a href="https://blog.csdn.net/v_JULY_v/article/details/81410574" target="_blank" rel="external">通俗理解kaggle比赛大杀器xgboost</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/18/Learning-to-rank算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jeb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小菜鸡">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/18/Learning-to-rank算法/" itemprop="url">Learning to rank算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-18T15:25:57+08:00">
                2019-11-18
              </time>
            

            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>互联网<strong>搜索</strong>诞生初期，检索模型使用的特征相对简单，这些特征主要基于query与doc之间的相关度来对文档进行排序。另一种传统排序模型是重要性排序模型，此时模型不考虑query ，而仅仅根据文档（网页）之间的图结构来判断doc的重要程度，例如PageRank排序模型。而随着互联网不断发展，海量数据的产生，更多复杂有效的特征被用于搜索排序，人工调参已不能满足需求，此时机器学习开始在搜索排序领域得到应用，learning to rank逐渐成为热门研究方向。</p>
<h2 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h2><p>搜索的目标是选择与用户输入query最相关的一组文档，目前主要步骤如下：</p>
<ol>
<li>粗排：query-doc匹配，得到一组与query相关的文档，目前一般采用倒排索引实现；</li>
<li>精排：选取更多特征，按照用户点击该doc的可能性大小排序，Learning to rank即是实现该部分的机器学习模型。</li>
</ol>
<h2 id="机器学习排序系统"><a href="#机器学习排序系统" class="headerlink" title="机器学习排序系统"></a>机器学习排序系统</h2><p>典型的机器学习排序系统如下图所示：<br><img src="/images/rank-system.jpg" alt=""></p>
<h2 id="Learning-to-rank"><a href="#Learning-to-rank" class="headerlink" title="Learning to rank"></a>Learning to rank</h2><p>包含pointwise方法、pairwise方法和listwise方法三种类型。</p>
<p>(1) pointwise方法：对于某一个query， 判断每个doc这个query的相关度，由此将docs排序问题转化为了分类（比如相关、不相关）或回归问题（相关程度越大，回归函数的值越大）。其L2R框架具有以下特征：</p>
<ul>
<li>输入空间中样本是单个 doc（和对应 query）构成的特征向量；</li>
<li>输出空间中样本是单个 doc（和对应 query）的相关度；</li>
<li>假设样本满足打分函数；</li>
<li>损失函数评估单个 doc 的预测得分和真实得分之间差异。</li>
</ul>
<p>(2) pairwise方法：该方法并不关心某一个doc与query相关程度的具体数值，而是将排序问题转化为任意两个不同的docs di和dj谁与当前的query更相关的相对顺序的排序问题。一般分为di比dj更相关、更不相关和相关程度相等三个类别，分别记为{+1, -1, 0}，由此便又转化为了分类问题。其 L2R 框架具有以下特征：</p>
<ul>
<li>输入空间中样本是（同一 query 对应的）两个 doc（和对应 query）构成的两个特征向量；</li>
<li>输出空间中样本是 pairwise preference；</li>
<li>假设空间中样本满足二变量函数；</li>
<li>损失函数评估 doc pair 的预测 preference 和真实 preference 之间差异。</li>
</ul>
<p>(3) listwise方法：将一个query对应的所有相关文档看做一个整体，作为单个训练样本。其 L2R 框架具有以下特征：</p>
<ul>
<li>输入空间中样本是（同一 query 对应的）所有 doc构成的多个特征向量（列表）；</li>
<li>输出空间中样本是这些 doc与对应 query的相关度排序列表；</li>
<li>假设空间中样本满足多变量函数，对于 docs 得到其排列，实践中，通常是一个打分函数，根据打分函数对所有 docs 的打分进行排序得到 docs 相关度的排列；</li>
<li>损失函数分成两类，一类是直接和评价指标相关的，还有一类不是直接相关的。</li>
</ul>
<p>由于评价指标通常是离散不可微的，直接优化ranking评价指标并不简单，通常有以下处理方式：</p>
<ul>
<li>优化基于评价指标的 ranking error 的连续可微的近似，这种方法就可以直接应用已有的优化方法，如SoftRank，ApproximateRank，SmoothRank。</li>
<li>优化基于评价指标的 ranking error 的连续可微的上界，如 SVM-MAP，SVM-NDCG，PermuRank。</li>
<li>使用可以优化非平滑目标函数的优化技术，如 AdaRank，RankGP。非直接相关的损失函数则不再使用与评价相关的loss来优化模型，而是设计能衡量模型输出与真实排列之间差异的 loss，如此获得的模型在评价指标上也能获得不错的性能。例如 ：ListNet，ListMLE，StructRank和BoltzRank。</li>
</ul>
<h3 id="主要模型分类"><a href="#主要模型分类" class="headerlink" title="主要模型分类"></a>主要模型分类</h3><p>按照这三种类型，可以将主要模型做如下梳理：<br><img width="600" src="/images/search_kinds.png"><br>图中Rank Creation指给定查询Query和文档Docs，得到Docs排序结果；Rank Aggregation指综合多个不同的Ranking System的排序结果，得出最终排序结果。</p>
<h3 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h3><p>下面以xgboost模型为例，说明如何完成排序。大致过程如下：<br><strong>训练</strong></p>
<ol>
<li>获取训练数据；</li>
<li>构造特征候选集，完成训练样本准备；</li>
<li>基于xgboost寻找划分点，重复该步至不能再分裂划分点；</li>
<li>通过最小化pairwise loss生成下一棵树；</li>
<li>生成设定数量的树后，训练完成；</li>
</ol>
<p><strong>测试</strong></p>
<ol>
<li>输入测试样本；</li>
<li>根据训练所得模型和打分函数进行打分；</li>
<li>获得每个<query,doc>对打分，并完成排序。</query,doc></li>
</ol>
<p>值得注意的是，目前使用比较多的XGBoost ranking模型是LambdaRank，但尚未完成，所以目前使用pairwise rank，参考<a href="https://github.com/dmlc/xgboost/tree/master/demo/rank" target="_blank" rel="external">dmlc/xgboost</a> .</p>
<p><strong>代码示例</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div></pre></td><td class="code"><pre><div class="line">import os,sys,json</div><div class="line">import math</div><div class="line">import random</div><div class="line">import numpy as np</div><div class="line">import pandas as pd</div><div class="line">import sklearn.utils</div><div class="line">import xgboost as xgb</div><div class="line"></div><div class="line">enableFeatures = [</div><div class="line">    &quot;fea1&quot;,</div><div class="line">    &quot;fea2&quot;</div><div class="line">]</div><div class="line"></div><div class="line">train_data = pd.read_csv(&quot;train.csv&quot;, sep=&quot;\t&quot;)</div><div class="line">test_data = pd.read_csv(&quot;test.csv&quot;, sep=&quot;\t&quot;)</div><div class="line">print(&quot;all data &#123;0&#125;&quot;.format(train_data.shape))</div><div class="line">print(&quot;all data &#123;0&#125;&quot;.format(test_data.shape))</div><div class="line"></div><div class="line"># 分组处理数据</div><div class="line">traingroups = &#123;&#125;</div><div class="line">validgroups = &#123;&#125;</div><div class="line"></div><div class="line">for qid, df in list(train_data.groupby(&quot;group_id&quot;)):</div><div class="line">    group = traingroups.setdefault(qid, &#123;&#125;)</div><div class="line">    group[&quot;length&quot;] = len(df)</div><div class="line">    group[&quot;weight&quot;] = 1</div><div class="line">    group[&quot;df&quot;] = df</div><div class="line"></div><div class="line">for qid, df in list(test_data.groupby(&quot;group_id&quot;)):</div><div class="line">    group = validgroups.setdefault(qid, &#123;&#125;)</div><div class="line">    group[&quot;length&quot;] = len(df)</div><div class="line">    group[&quot;weight&quot;] = 1</div><div class="line">    group[&quot;df&quot;] = df</div><div class="line"></div><div class="line">print(&quot;groups&quot;)</div><div class="line">traingroups = [group for qid, group in traingroups.items() ]</div><div class="line">validgroups = [group for qid, group in validgroups.items() ]</div><div class="line"></div><div class="line">print(&quot;concat&quot;)</div><div class="line">train_X = pd.concat(map(lambda x: sklearn.utils.shuffle(x[&quot;df&quot;]), traingroups), ignore_index=True)</div><div class="line">valid_X = pd.concat(map(lambda x: sklearn.utils.shuffle(x[&quot;df&quot;]), validgroups), ignore_index=True)</div><div class="line">train_y = train_X[&quot;label&quot;]</div><div class="line">valid_y = valid_X[&quot;label&quot;]</div><div class="line"></div><div class="line">train_X = train_X[enableFeatures]</div><div class="line">valid_X = valid_X[enableFeatures]</div><div class="line">train_X, valid_X = train_X.align(valid_X, join=&quot;left&quot;, axis=1)</div><div class="line"></div><div class="line">print(&quot;data length weight&quot;)</div><div class="line">train_q = np.array(list(map(lambda x: x[&quot;length&quot;], traingroups)))</div><div class="line">valid_q = np.array(list(map(lambda x: x[&quot;length&quot;], validgroups)))</div><div class="line">train_w = np.array(list(map(lambda x: x[&quot;weight&quot;], traingroups)))</div><div class="line">valid_w = np.array(list(map(lambda x: x[&quot;weight&quot;], validgroups)))</div><div class="line"></div><div class="line">print(&quot;model train&quot;)</div><div class="line">#&quot;rank:ndcg&quot;</div><div class="line">ranker = xgb.XGBRanker(objective=&quot;rank:pairwise&quot;)</div><div class="line">ranker.fit(train_X, train_y, train_q, sample_weight=train_w,</div><div class="line">    eval_set=[(valid_X, valid_y)], eval_group=[valid_q], sample_weight_eval_set=[valid_w],</div><div class="line">    eval_metric=[&quot;ndcg@5-&quot;, &quot;ndcg@10-&quot;], early_stopping_rounds=5, verbose=True,</div><div class="line">    callbacks=[xgb.callback.reset_learning_rate(lambda x,y: 0.95 ** x * 0.1)])</div><div class="line">ranker.feature_names = map(str, train_X.columns)</div><div class="line">with open(&quot;xgb_pair.model.features&quot;, &quot;w&quot;) as fw:</div><div class="line">    fw.write( &quot;,&quot;.join(ranker.feature_names))</div><div class="line">ranker.save_model(&apos;xgb_pair.model&apos;)</div><div class="line">model = xgb.Booster(model_file=&apos;xgb_pair.model&apos;)</div><div class="line">print(ranker.get_booster().get_score(importance_type=&apos;gain&apos;) )</div></pre></td></tr></table></figure></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://blog.csdn.net/seasongirl/article/details/100178083" target="_blank" rel="external">用xgboost做排序任务——xgboost下的learning2rank</a><br><a href="https://blog.csdn.net/zuolixiangfisher/article/details/81072922" target="_blank" rel="external">Learning to Rank系列之概述</a><br><a href="http://www.bdpt.net/cn/2018/11/20/rank教程-06-learning-to-rank-概述/" target="_blank" rel="external">Learning to Rank 概述</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/05/31/BERT二阶段fine-tune代码分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jeb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小菜鸡">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/31/BERT二阶段fine-tune代码分析/" itemprop="url">BERT二阶段fine tune代码分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-31T16:56:20+08:00">
                2019-05-31
              </time>
            

            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>BERT除预训练代码run_pretraining.py外，还提供了run_classifier.py用于文本分类和run_squad.py用于阅读理解，下面通过对比三个代码总结出如何快速基于BERT做二阶段fine tune的方法。此外，如果TF Hub中有对应任务可使用的预训练模型，也可直接使用，例如同样用于分类的run_classifier_with_tfhub.py。</p>
<h2 id="代码整体结构"><a href="#代码整体结构" class="headerlink" title="代码整体结构"></a>代码整体结构</h2><p>代码的整体流程如下图所示：<br><img src="/images/BERT.png" alt=""></p>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>在bert_config_file文件中配置各个参数，例如attention_probs_dropout_prob和directionality等，config文件在BERT提供的预训练模型中。</p>
<h3 id="输入处理"><a href="#输入处理" class="headerlink" title="输入处理"></a>输入处理</h3><p>结构图中以get input files表示整个的输入数据处理部分，不同于早期版本的数据处理过程，当前的TF版本将数据转化为features用于训练。所以需要建立相应的结构体承接数据，并建立对应的数据处理方法，最后转化为features，下表中convert_exps_to_features为convert_examples_to_features简写。</p>
<table>
<thead>
<tr>
<th>代码/功能</th>
<th>承接数据</th>
<th>数据处理方法</th>
<th>转化为features</th>
</tr>
</thead>
<tbody>
<tr>
<td>run_classifier.py</td>
<td>InputExample, InputFeatures</td>
<td>DataProcessor</td>
<td>convert_single_example</td>
</tr>
<tr>
<td>run_squad.py</td>
<td>SquadExample, InputFeatures</td>
<td>read_squad_examples</td>
<td>convert_exps_to_features</td>
</tr>
</tbody>
</table>
<h3 id="建立模型"><a href="#建立模型" class="headerlink" title="建立模型"></a>建立模型</h3><p>以run_classifier.py为例，使用model_fn_builder函数建立模型。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">model_fn = model_fn_builder(</div><div class="line">      bert_config=bert_config,</div><div class="line">      num_labels=len(label_list),</div><div class="line">      init_checkpoint=FLAGS.init_checkpoint,</div><div class="line">      learning_rate=FLAGS.learning_rate,</div><div class="line">      num_train_steps=num_train_steps,</div><div class="line">      num_warmup_steps=num_warmup_steps,</div><div class="line">      use_tpu=FLAGS.use_tpu,</div><div class="line">      use_one_hot_embeddings=FLAGS.use_tpu)</div></pre></td></tr></table></figure></p>
<p>具体地，将配置、训练数据等信息传入create_model函数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">(total_loss, per_example_loss, logits, probabilities) = create_model(</div><div class="line">        bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,</div><div class="line">        num_labels, use_one_hot_embeddings)</div></pre></td></tr></table></figure></p>
<p>create_model函数首先基于BERT建立模型。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">model = modeling.BertModel(</div><div class="line">      config=bert_config,</div><div class="line">      is_training=is_training,</div><div class="line">      input_ids=input_ids,</div><div class="line">      input_mask=input_mask,</div><div class="line">      token_type_ids=segment_ids,</div><div class="line">      use_one_hot_embeddings=use_one_hot_embeddings)</div></pre></td></tr></table></figure></p>
<p>然后根据需要取得BERT模型的输出，例如在run_classifier.py中:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">output_layer = model.get_pooled_output()</div></pre></td></tr></table></figure></p>
<p>run_squad.py中:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">final_hidden = model.get_sequence_output()</div></pre></td></tr></table></figure></p>
<p>此部分相当于利用BERT作为一个Encoder来编码输入信息，随后便可根据任务定义对应的可学习参数和loss。</p>
<h3 id="建立estimator"><a href="#建立estimator" class="headerlink" title="建立estimator"></a>建立estimator</h3><p>根据已建立的模型和配置信息新建estimator。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">estimator = tf.contrib.tpu.TPUEstimator(</div><div class="line">      use_tpu=FLAGS.use_tpu,</div><div class="line">      model_fn=model_fn,</div><div class="line">      config=run_config,</div><div class="line">      train_batch_size=FLAGS.train_batch_size,</div><div class="line">      predict_batch_size=FLAGS.predict_batch_size)</div></pre></td></tr></table></figure></p>
<h3 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h3><p>使用input_fn_builder建立训练数据，输入estimator开始训练。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">train_input_fn = input_fn_builder(</div><div class="line">        input_file=train_writer.filename,</div><div class="line">        seq_length=FLAGS.max_seq_length,</div><div class="line">        is_training=True,</div><div class="line">        drop_remainder=True)</div><div class="line">    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)</div></pre></td></tr></table></figure></p>
<h2 id="使用TF-Hub"><a href="#使用TF-Hub" class="headerlink" title="使用TF Hub"></a>使用TF Hub</h2><p>run_classifier_with_tfhub.py与run_classifier.py整体流程非常类似，区别在于run_classifier_with_tfhub.py中获得BERT模型是通过TF Hub。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bert_module = hub.Module(bert_hub_module_handle, tags=tags, trainable=True)</div></pre></td></tr></table></figure></p>
<p>获得BERT模型输出时需要指定signature。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">bert_outputs = bert_module(</div><div class="line">      inputs=bert_inputs,</div><div class="line">      signature=&quot;tokens&quot;,</div><div class="line">      as_dict=True)</div></pre></td></tr></table></figure></p>
<p>其他部分与run_classifier.py类似。</p>
<h2 id="新任务"><a href="#新任务" class="headerlink" title="新任务"></a>新任务</h2><p>对于一个新任务，可参考run_classifier.py代码进行修改，主要修改数据处理、模型建立等部分，具体地，InputExample，InputFeatures，convert_examples_to_features和create_model函数等。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/05/15/文本查重-SimHash和MinHash算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jeb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小菜鸡">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/15/文本查重-SimHash和MinHash算法/" itemprop="url">文本查重-SimHash和MinHash算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-15T15:16:45+08:00">
                2019-05-15
              </time>
            

            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p>SimHash和MinHash算法主要应用于海量文本查重，两者都属于<a href="https://www.cnblogs.com/wt869054461/p/8148940.html" target="_blank" rel="external">局部敏感哈希</a>（Locality-Sensitive Hashing, LSH）算法，而LSH又是<a href="http://www.cnblogs.com/ljygoodgoodstudydaydayup/p/10519253.html" target="_blank" rel="external">近似最近邻查找</a>（Approximate Nearest  Neighbor, ANN）中的一类算法，其主要思想是利用降维和索引，加快查找过程。</p>
<h2 id="SimHash"><a href="#SimHash" class="headerlink" title="SimHash"></a>SimHash</h2><p>算法的过程如下图所示：<br><img src="http://dl.iteye.com/upload/attachment/437426/baf42378-e625-35d2-9a89-471524a355d8.jpg" alt=""><br>具体过程为：</p>
<ol>
<li>确定文本Doc中各个词语（中文需分词）的权重，方法可以有多种，例如TfIdf和TextRank算法，则文档可表示为(feature, weight)组成的向量；</li>
<li>初始化一个长度为64位（可综合空间和时间复杂度考虑具体数值）的Doc特征向量，各元素初始化为0；</li>
<li>对Doc中每个词语利用hash函数计算一个长度为64位的特征向量；</li>
<li>遍历词语特征向量，如果第i位为1，则Doc特征向量对应位+w，否则-w；</li>
<li>所有词语处理完毕后，判断Doc特征向量的每一位，如果大于0，则置1，否则置0；</li>
<li>获得各Doc的特征向量后，可利用海明距离判断两篇文档的相似性，一般地，距离&lt;=3时认为两者是相似的。</li>
</ol>
<p>上述过程可以理解为Doc的特征降维过程，我们将降维后的特征向量成为fingerprints。完成降维后，我们需要思考如何设计索引来加快查找过程。<br>第一种方案是对查询向量Q进行变化，查找64位所有3位以内的变化的组合，如下图所示：<br><img src="http://dl.iteye.com/upload/attachment/438114/ae5a47cb-068c-32b6-a4d5-6a5b808b0b26.jpg" alt=""><br>单一内容Q需要进行四万多次查询，时间复杂度太高。<br>第二种方案是对已生成Doc的fingerprints进行3位以内的组合变化，但需要多占据四万多倍的原始空间，如下图所示：<br><img src="http://dl.iteye.com/upload/attachment/437527/d31f3880-d43e-33ac-89c3-3e11a3f4f95e.jpg" alt=""><br>如何找到一种空间和时间的平衡呢？假设海明距离在3以内的两个文档是相似的，那么只要将64位的二进制串分为4块，根据鸽巢原理，两个文档的fingerprints中至少有一块是完全相同的，如下图所示：<br><img src="http://dl.iteye.com/upload/attachment/437559/689719df-54b7-318c-bc90-e289f84344b9.jpg" alt=""><br>由于查询时无法预知是哪一块区域相同，因此需要对四块中的每一块都建立索引，假设样本库中有<span>$2^32$</span><!-- Has MathJax -->，约43亿的fingerprints，那么每个table中包含<span>$2^(32-16)$</span><!-- Has MathJax -->=65536个候选结果，大大减少了海明距离的计算成本。上图所示的索引结构在MongoDB中实现非常简单。此外，索引块数k和table中候选结果数量m也是一个平衡抉择的过程，k越大，m越小，空间复杂度升高；k越小，m越大，时间复杂度升高。下图是k=4时索引示意图：<br><img src="http://dl.iteye.com/upload/attachment/437586/b72b8dc2-9139-3078-ad24-b689f64fd71a.jpg" alt=""></p>
<h2 id="MinHash"><a href="#MinHash" class="headerlink" title="MinHash"></a>MinHash</h2><p>与SimHash不同，MinHash要从衡量两个文档的相似度说起。Jaccard相似度用于描述两个集合的相似程度，假设有两个集合A和B，相似度=A与B交集的元素个数／A与B并集的元素个数，公式为：<br><span>$$\begin{gather*}
J(A, B)=\frac{|A \cap B|}{|A \cup B|}
\end{gather*}$$</span><!-- Has MathJax --><br>海量文本直接求Jaccard相似度复杂度太高，两个文档需要逐个词比较，为降低复杂度，我们使用两个文档的最小哈希值相等的概率来等价于两个文档的Jaccard相似度，并可以证明两者是相等的。首先说明一下如何求一个集合的最小哈希值，假设现在有4个集合，分别为S1，S2，S3，S4；其中，S1={a,d}, S2={c}, S3={b,d,e}, S4={a,c,d}，所以全集U={a,b,c,d,e}。我们可以构造如下0-1矩阵：</p>
<table>
<thead>
<tr>
<th>元素</th>
<th>S1</th>
<th>S2</th>
<th>S3</th>
<th>S4</th>
</tr>
</thead>
<tbody>
<tr>
<td>a</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>b</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>c</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>d</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>e</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>为得到各集合的最小哈希值，首先对矩阵进行随机行打乱，则某个集合（某一列）的最小哈希值就等于打乱后第一个值为1的行所在的行号。定义一个最小哈希函数h，用于模拟对矩阵进行随机打乱，假设打乱后的矩阵如下表所示：</p>
<table>
<thead>
<tr>
<th>元素</th>
<th>S1</th>
<th>S2</th>
<th>S3</th>
<th>S4</th>
</tr>
</thead>
<tbody>
<tr>
<td>b</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>e</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>a</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>d</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>c</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>则h(S1)=2, h(S2)=4, h(S3)=0, h(S4)=2。经过随机打乱后，两个集合的最小哈希值相等的概率=两集合的Jaccard的相似度证明如下：</p>
<blockquote>
<p>仅考虑集合S1和S2，那么这两列所在的行有以下三种情况：</p>
<ol>
<li>S1和S2的值都为1，用X表示；</li>
<li>一个值为1，另一个为0，用Y表示；</li>
<li>S1和S2的值都为0，用Z表示。</li>
</ol>
</blockquote>
<p>S1与S2的交集元素个数为X，并集个数为X+Y，所以sim(S1,S2)=Jaccard(S1,S2)=X/(X+Y)。随机打乱后h(S1)=h(S2)的概率等于从上往下扫描，在遇到Y行之前遇到X行的概率（Z行没有影响），或者说把X个黑球和Y个白球放入一个袋子中，首次拿到黑球的概率，即h(S1)=h(S2)的概率为X/(X+Y)。假设特征矩阵很大时，对其进行打乱非常耗时，而且要进行多次打乱，其实可以通过多个随机哈希函数来模拟打乱的效果。具体地，定义n个随机哈希函数$h_1, h_2,…,h_n$，sig(i,j)表示签名矩阵中第i个哈希函数在第j列上的元素，将签名矩阵中各个元素sig(i,j)初始化为inf(无穷大)，对原矩阵中每一行r：</p>
<ol>
<li>计算<span>$h_1(r),h_2(r),...,h_n(r)$</span><!-- Has MathJax -->；</li>
<li>对于每一列j：<ul>
<li>如果j所在的第r行为0，什么都不做；</li>
<li>如果j所在的第r行为1，则对每个i=1,2,…,n，<span>$sig(i,j)=min(sig(i,j), h_i(r))$</span><!-- Has MathJax --></li>
</ul>
</li>
</ol>
<p>例如<span>$h_1(x)=(x+1)%5, h_2(x)=(3*x+1)%5$</span><!-- Has MathJax -->，则经过上述操作可获得如下的签名矩阵：</p>
<table>
<thead>
<tr>
<th>哈希函数</th>
<th>S1</th>
<th>S2</th>
<th>S3</th>
<th>S4</th>
</tr>
</thead>
<tbody>
<tr>
<td>$h_1$</td>
<td>1</td>
<td>3</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>$h_2$</td>
<td>0</td>
<td>2</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>上述获得各文档签名矩阵可以理解为一个降维过程，获得签名后，假如数据量十分庞大的话，两两比较的话计算复杂度仍然非常高，所以需要类似SimHash索引分块的方法来降低查询复杂度。当一个新文档到达时，希望仅比较与其相似性较高的文档，忽略相似性较低的集合。如下图所示，假设签名矩阵有12行，我们将3行为一组放进一个“桶”里：<br><img width="500" src="/images/bucket.png"><br>对于S2，仅需要查询与其具有相同桶的集合，如下图所示：<br><img width="500" src="/images/bucket5.png"><br>即只需要查询S4和S5。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote>
<p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.295.8001&amp;rep=rep1&amp;type=pdf" target="_blank" rel="external">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.295.8001&amp;rep=rep1&amp;type=pdf</a><br><a href="https://blog.csdn.net/heiyeshuwu/article/details/44117473" target="_blank" rel="external">https://blog.csdn.net/heiyeshuwu/article/details/44117473</a><br><a href="https://www.cnblogs.com/sddai/p/6110704.html" target="_blank" rel="external">https://www.cnblogs.com/sddai/p/6110704.html</a></p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/05/14/TextRank算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jeb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小菜鸡">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/14/TextRank算法/" itemprop="url">TextRank算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-14T15:25:17+08:00">
                2019-05-14
              </time>
            

            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p>TextRank算法可以用于提取文本关键词和生成摘要，其思想来源于PageRank算法。Google的两位创始人在斯坦福大学读研期间从事网页排序研究时，受到学术界对学术论文重要性的评估方法（论文引用次数）启发，提出了PageRank算法。PageRank算法的核心思想比较直观：</p>
<ol>
<li>如果一个网页被很多其他网页链接到，说明这个网页很重要，对应的PR(PageRank)值也越高；</li>
<li>如果一个PR值较高的网页链接了某个网页，则该网页的PR值也会相应提高。</li>
</ol>
<h2 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h2><h3 id="PageRank"><a href="#PageRank" class="headerlink" title="PageRank"></a>PageRank</h3><p>将网页之间的链接抽象为一张有向图，如下图所示：<br><img width="500" src="/images/dgraph.png"></p>
<p><center><strong><em><a href="https://www.cnblogs.com/mcomco/p/10304383.html" target="_blank" rel="external">图片来源</a></em></strong></center><br>图结构构造完成后，可使用以下公式计算网页的PR值：<br><span>$$\begin{gather*}
S\left(V_{i}\right)=(1-d)+d * \sum_{j \in I n\left(V_{i}\right)} \frac{1}{\left|O u t\left(V_{j}\right)\right|} S\left(V_{j}\right)
\end{gather*}$$</span><!-- Has MathJax --><br><span>$S\left(V_{i}\right)$</span><!-- Has MathJax -->表示网页i的PR值，即网页的重要性指标。d是阻尼系数，一般取0.85。<span>$I n\left(V_{i}\right)$</span><!-- Has MathJax -->表示指向网页i的网页集合。<span>$|O u t\left(V_{j}\right)|$</span><!-- Has MathJax -->表示网页j指向的网页总数，<span>$S\left(V_{j}\right)$</span><!-- Has MathJax -->表示网页j的PR值。可将各网页PR值设置为1，经过多次迭代，满足收敛条件后获得各个网页的PR值。</p>
<blockquote>
<p>阻尼系数:</p>
<p>PageRank算法可以视为对网页跳转的模拟，当有些网页只有入链而没有出链时，则无法从这些网页跳转出去，使得每个网页的PageRank值最终为0。下图给出了这个问题的实例，网页C没有到其他页面的链接，随着算法的不断迭代，每个网页的权重值不断减少，最终收敛于0。为了避免这个问题，在算法中引入阻尼系数d，作为网页随机跳转的概率。</p>
</blockquote>
<h3 id="TextRank"><a href="#TextRank" class="headerlink" title="TextRank"></a>TextRank</h3><h4 id="关键词提取"><a href="#关键词提取" class="headerlink" title="关键词提取"></a>关键词提取</h4><p>以下面的文章为例，首先进行过滤停用词等预处理（中文需要分词），然后建立如图所示单词之间的连接图，此时PageRank算法中网页之间的链接关系体现为一定窗口大小内单词之间的相邻关系，例如以“systems”为中心，窗口大小为3时，”types”, “linear”和“compatibility”与其具有“链接关系“。<br><img src="/images/keywords.png" alt=""></p>
<p><center><strong><em><a href="https://upload-images.jianshu.io/upload_images/3579920-09c220dd15b3f13b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/996" target="_blank" rel="external">图片来源</a></em></strong></center><br>图构造完成后，单词的TR值计算公式为：<br><span>$$\begin{gather*}
W S\left(V_{i}\right)=(1-d)+d * \sum_{V_{j} \in I n\left(V_{i}\right)} \frac{w_{j i}}{\sum_{V_{k} \in O u t\left(V_{j}\right)} w_{j k}} W S\left(V_{j}\right)
\end{gather*}$$</span><!-- Has MathJax --><br>TR值计算公式与PR值十分类似，区别在于加入了一个参数<span>$w_{j i}$</span><!-- Has MathJax -->，一般来说<span>$w_{j i}$</span><!-- Has MathJax -->的值为文章中第j个单词和第i个单词在一定窗口大小的共现次数。后续的迭代过程与PR值计算类似。</p>
<h4 id="摘要生成"><a href="#摘要生成" class="headerlink" title="摘要生成"></a>摘要生成</h4><p>将文本中的每个句子看作图中的一个节点，句子之间的“链接关系”由句子间的相似性体现。句子相似性有多种计算方式，这里使用一种很简单的方法，计算两个句子共有词比例。句子相似性公式：<br><span>$$\begin{gather*}
\text {Similarity}\left(S_{i}, S_{j}\right)=\frac{\left|\left\{w_{k} | w_{k} \in S_{i} \&amp; w_{k} \in S_{j}\right\}\right|}{\log \left(\left|S_{i}\right|\right)+\log \left(\left|S_{j}\right|\right)}
\end{gather*}$$</span><!-- Has MathJax --><br><span>$S_{i}, S_{j}$</span><!-- Has MathJax -->分别表示第i个和第j个句子，$w_{k}$表示句子中的词语，公式中分子表示两个句子共有词的个数，分母表示两个句子词总数对数求和。后续TR值计算和迭代过程与关键词提取类似。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote>
<p><a href="http://www.cnblogs.com/xueyinzhe/p/7101295.html" target="_blank" rel="external">http://www.cnblogs.com/xueyinzhe/p/7101295.html</a><br><a href="https://blog.csdn.net/woshiliulei0/article/details/81479434" target="_blank" rel="external">https://blog.csdn.net/woshiliulei0/article/details/81479434</a></p>
</blockquote>
<p><strong><em>本文中图片均来自互联网</em></strong></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/05/07/使用TensorFlow-Serving快速部署模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jeb">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小菜鸡">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/07/使用TensorFlow-Serving快速部署模型/" itemprop="url">使用TensorFlow Serving快速部署模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-07T11:41:42+08:00">
                2019-05-07
              </time>
            

            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="工业产品中TensorFlow使用方法"><a href="#工业产品中TensorFlow使用方法" class="headerlink" title="工业产品中TensorFlow使用方法"></a>工业产品中TensorFlow使用方法</h1><ol>
<li>用TensorFlow的C++/Java/Nodejs API直接使用保存的TensorFlow模型：类似Caffe，适合做桌面软件。</li>
<li>直接将使用TensorFlow的Python代码放到Flask等Web程序中，提供Restful接口：实现和调试方便，但效率不太高，不大适合高负荷场景，且没有版本管理、模型热更新等功能。</li>
<li>将TensorFlow模型托管到TensorFlow Serving中，提供RPC或Restful服务：实现方便，高效，自带版本管理、模型热更新等，很适合大规模线上业务。</li>
</ol>
<blockquote>
<p>参考链接：<a href="https://cloud.tencent.com/developer/article/1375668" target="_blank" rel="external">https://cloud.tencent.com/developer/article/1375668</a> </p>
</blockquote>
<h1 id="TensorFlow-Serving简介"><a href="#TensorFlow-Serving简介" class="headerlink" title="TensorFlow Serving简介"></a>TensorFlow Serving简介</h1><p><a href="https://github.com/tensorflow/serving" target="_blank" rel="external">Tensorflow Serving</a>是Google官方提供的模型部署方式，正确导出模型后，可一分钟完成部署（官方广告）。TF1.8后，Tensorflow Serving支持RESTfull API和grpc的请求方式，模型部署完成后可很方便的利用post请求进行测试。</p>
<h1 id="TensorFlow-Serving服务框架"><a href="#TensorFlow-Serving服务框架" class="headerlink" title="TensorFlow Serving服务框架"></a>TensorFlow Serving服务框架</h1><p>框架分为模型训练、模型上线和服务使用三部分。模型训练与正常的训练过程一致，只是导出时需要按照TF Serving的标准定义输入、输出和签名。模型上线时指定端口号和模型路径后，通过tensorflow_model_server命令启动服务。服务使用可通过grpc和RESTfull方式请求。<br><img width="724" src="https://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_jpg/rFWVXwibLGtzxrqiba6BicbqCjDDQ313ohCZJQ5u0LTnK5okv89ibHbf2pI6YWMq05UNjjoiaxxibxd6pqk6l07T04rA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1"></p>
<h1 id="模型导出"><a href="#模型导出" class="headerlink" title="模型导出"></a>模型导出</h1><p>需指定模型的输入和输出，并在tags中包含”serve”，在实际使用中，TF Serving要求导出模型包含”serve”这个tag。此外，还需要指定默认签名，tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY = “serving_default”，此外tf.saved_model.signature_constants定义了三类签名，分别是：</p>
<ul>
<li>分类classify</li>
<li>回归regress</li>
<li>预测predict</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">CLASSIFY_METHOD_NAME = &quot;tensorflow/serving/classify&quot;</div><div class="line">PREDICT_METHOD_NAME = &quot;tensorflow/serving/predict&quot;</div><div class="line">REGRESS_METHOD_NAME = &quot;tensorflow/serving/regress&quot;</div></pre></td></tr></table></figure>
<p>一般而言，用predict就完事了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">with sess.graph.as_default() as graph:</div><div class="line">    builder = tf.saved_model.builder.SavedModelBuilder(saved_model_dir)</div><div class="line">    signature = tf.saved_model.signature_def_utils.predict_signature_def(inputs=&#123;&apos;image&apos;: in_image&#125;,</div><div class="line">                                      outputs=&#123;&apos;prediction&apos;: graph.get_tensor_by_name(&apos;final_result:0&apos;)&#125;,)</div><div class="line">    builder.add_meta_graph_and_variables(sess=sess,</div><div class="line">                                         tags=[&quot;serve&quot;],</div><div class="line">                                         signature_def_map=&#123;&apos;predict&apos;:signature, tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:signature&#125;)</div><div class="line">    builder.save()</div></pre></td></tr></table></figure></p>
<h1 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=模型名 --model_base_path=模型所在路径</div></pre></td></tr></table></figure>
<h1 id="请求服务"><a href="#请求服务" class="headerlink" title="请求服务"></a>请求服务</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">curl -d &apos;&#123;&quot;inputs&quot;: [[1.1,1.2,0.8,1.3]]&#125;&apos; -X POST http://localhost:8501/v1/models/模型名:predict</div></pre></td></tr></table></figure>
<p>python可以通过post请求，golang可以通过grpc服务请求。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          
            <img class="site-author-image" itemprop="image"
              src="/images/avatar.gif"
              alt="Jeb" />
          
            <p class="site-author-name" itemprop="name">Jeb</p>
            <p class="site-description motion-element" itemprop="description">我菜故我在</p>
        </div>

        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives/">
            
                <span class="site-state-item-count">26</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jeb</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动</div>

  <span class="post-meta-divider">|</span>

  <div class="theme-info">主题 &mdash; <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.2</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  


  




	





  





  








  





  

  

  

  

  

  

</body>
</html>
